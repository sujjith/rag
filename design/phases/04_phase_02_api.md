# Phase 2: REST API + Testing

> **Goal**: Expose the Phase 1 RAG system as a REST API with proper testing, error handling, and Docker deployment.

---

## Overview

This phase transforms the CLI-based RAG system into a production-ready REST API. By the end, you'll have:

1. FastAPI REST endpoints for ingestion and querying
2. Comprehensive error handling with retries
3. Structured logging
4. Unit and integration tests
5. Docker containerization
6. API documentation (auto-generated by FastAPI)

---

## Technology Stack (Phase 2)

| Component | Choice | Why |
|-----------|--------|-----|
| **Web Framework** | FastAPI | Async, auto-docs, Pydantic integration |
| **Validation** | Pydantic v2 | Already used in Phase 1, excellent validation |
| **Testing** | pytest + pytest-asyncio | Async support, fixtures |
| **Mocking** | unittest.mock | Standard library, no extra deps |
| **Logging** | structlog | Structured JSON logging |
| **Retries** | tenacity | Decorator-based retry logic |
| **Containerization** | Docker + docker-compose | Standard deployment |

---

## Architecture (Phase 2)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                     Phase 2: API Architecture                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│   Client (curl, Postman, Frontend)                                      │
│       │                                                                  │
│       ▼                                                                  │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │                      FastAPI Application                         │   │
│   ├─────────────────────────────────────────────────────────────────┤   │
│   │  POST /api/v1/documents/ingest     (Upload & process docs)      │   │
│   │  POST /api/v1/query                (Ask questions)              │   │
│   │  GET  /api/v1/documents            (List documents)             │   │
│   │  GET  /api/v1/documents/{id}       (Get document details)       │   │
│   │  DELETE /api/v1/documents/{id}     (Delete document)            │   │
│   │  GET  /api/v1/health               (Health check)               │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│       │                                                                  │
│       ▼                                                                  │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │                    Service Layer                                 │   │
│   │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐  │   │
│   │  │  Ingestion  │  │  Retrieval  │  │  Generation (LLM)       │  │   │
│   │  │  Service    │  │  Service    │  │  Service                │  │   │
│   │  └─────────────┘  └─────────────┘  └─────────────────────────┘  │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│       │                                                                  │
│       ▼                                                                  │
│   ┌─────────────────────────────────────────────────────────────────┐   │
│   │                    Phase 1 Components                            │   │
│   │  DocumentLoader │ Chunker │ Embedder │ QdrantStore │ GroqLLM    │   │
│   └─────────────────────────────────────────────────────────────────┘   │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Python Concepts You'll Learn

| Concept | Where Used |
|---------|------------|
| FastAPI decorators & routing | API endpoints |
| Pydantic models & validators | Request/Response schemas |
| Dependency injection | Service instantiation |
| Abstract Base Classes (ABC) | Service interfaces |
| Custom exceptions | Error handling |
| Decorators (custom) | Retry logic, logging |
| Context managers | Resource cleanup |
| Async/await patterns | API handlers |
| pytest fixtures | Test setup/teardown |
| Mocking with unittest.mock | Isolating tests |

---

## Project Structure

```
rag_v1/
├── pyproject.toml
├── .env
├── Dockerfile
├── docker-compose.yml
│
├── src/
│   └── rag/
│       ├── __init__.py
│       ├── config.py              # (Phase 1)
│       ├── models.py              # (Phase 1)
│       ├── exceptions.py          # NEW: Custom exceptions
│       ├── logging_config.py      # NEW: Structured logging
│       │
│       ├── api/                   # NEW: FastAPI layer
│       │   ├── __init__.py
│       │   ├── main.py            # FastAPI app & lifespan
│       │   ├── routes/
│       │   │   ├── documents.py   # Document endpoints
│       │   │   ├── query.py       # Query endpoints
│       │   │   └── health.py      # Health check
│       │   ├── schemas/           # Pydantic schemas
│       │   │   ├── documents.py
│       │   │   ├── query.py
│       │   │   └── common.py
│       │   └── dependencies.py    # Dependency injection
│       │
│       ├── services/              # NEW: Business logic layer
│       │   ├── __init__.py
│       │   ├── base.py            # Abstract base classes
│       │   ├── ingestion.py       # Ingestion service
│       │   ├── retrieval.py       # Retrieval service
│       │   └── generation.py      # LLM generation service
│       │
│       ├── ingestion/             # (Phase 1)
│       ├── embeddings/            # (Phase 1)
│       ├── vectorstore/           # (Phase 1)
│       ├── retrieval/             # (Phase 1)
│       ├── llm/                   # (Phase 1)
│       └── cli.py                 # (Phase 1)
│
├── tests/
│   ├── conftest.py                # Shared fixtures
│   ├── unit/
│   │   ├── test_chunker.py
│   │   ├── test_embedder.py
│   │   ├── test_services.py
│   │   └── test_schemas.py
│   └── integration/
│       ├── test_api_documents.py
│       ├── test_api_query.py
│       └── test_rag_pipeline.py
│
└── data/
    └── documents/
```

---

## Implementation Tasks

| # | Task | Priority | Python Concepts | Files |
|---|------|----------|-----------------|-------|
| 1 | Add new dependencies | High | `pyproject.toml` | `pyproject.toml` |
| 2 | Custom exceptions | High | Exception classes, inheritance | `exceptions.py` |
| 3 | Structured logging | High | `structlog`, formatters | `logging_config.py` |
| 4 | Pydantic schemas | High | Pydantic v2, validators | `api/schemas/` |
| 5 | Service layer | High | ABC, dependency injection | `services/` |
| 6 | FastAPI main app | High | Lifespan, middleware | `api/main.py` |
| 7 | Document endpoints | High | File uploads, async | `api/routes/documents.py` |
| 8 | Query endpoints | High | Request/Response models | `api/routes/query.py` |
| 9 | Health check | Medium | Dependency checks | `api/routes/health.py` |
| 10 | Retry decorators | High | tenacity, decorators | Update services |
| 11 | Unit tests | High | pytest, mocking | `tests/unit/` |
| 12 | Integration tests | High | pytest-asyncio, TestClient | `tests/integration/` |
| 13 | Docker setup | Medium | Multi-stage builds | `Dockerfile`, `docker-compose.yml` |

---

## Step-by-Step Implementation

### Step 1: Add New Dependencies

```bash
# Add API dependencies
uv add fastapi uvicorn[standard] python-multipart

# Add logging & retries
uv add structlog tenacity

# Add testing dependencies
uv add --dev pytest pytest-asyncio pytest-cov httpx
```

**Update pyproject.toml:**
```toml
[project]
name = "rag-system"
version = "0.2.0"
description = "Open source RAG system with REST API"
requires-python = ">=3.11"

dependencies = [
    # Phase 1 dependencies
    "sentence-transformers>=2.2.0",
    "qdrant-client>=1.7.0",
    "groq>=0.4.0",
    "pymupdf>=1.23.0",
    "python-docx>=1.1.0",
    "click>=8.1.0",
    "rich>=13.0.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.5.0",
    "pydantic-settings>=2.1.0",
    # Phase 2 dependencies
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "python-multipart>=0.0.6",
    "structlog>=24.1.0",
    "tenacity>=8.2.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "pytest-cov>=4.1.0",
    "httpx>=0.26.0",
    "ruff>=0.1.0",
    "mypy>=1.8.0",
]

[project.scripts]
rag = "rag.cli:main"
```

---

### Step 2: Custom Exceptions

```python
# src/rag/exceptions.py
"""Custom exceptions for the RAG system."""

class RAGException(Exception):
    """Base exception for RAG system."""

    def __init__(self, message: str, details: dict = None):
        self.message = message
        self.details = details or {}
        super().__init__(self.message)


class DocumentNotFoundError(RAGException):
    """Raised when a document is not found."""
    pass


class DocumentProcessingError(RAGException):
    """Raised when document processing fails."""
    pass


class EmbeddingError(RAGException):
    """Raised when embedding generation fails."""
    pass


class VectorStoreError(RAGException):
    """Raised when vector store operations fail."""
    pass


class LLMError(RAGException):
    """Raised when LLM generation fails."""
    pass


class ValidationError(RAGException):
    """Raised when input validation fails."""
    pass


class RetryExhaustedError(RAGException):
    """Raised when all retry attempts are exhausted."""
    pass
```

---

### Step 3: Structured Logging

```python
# src/rag/logging_config.py
"""Structured logging configuration."""
import logging
import sys
import structlog
from rag.config import settings


def setup_logging(json_format: bool = True) -> None:
    """Configure structured logging."""

    # Set log level from settings (add LOG_LEVEL to config.py)
    log_level = getattr(settings, "log_level", "INFO")

    # Configure structlog processors
    shared_processors = [
        structlog.contextvars.merge_contextvars,
        structlog.processors.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
    ]

    if json_format:
        # JSON format for production
        processors = shared_processors + [
            structlog.processors.format_exc_info,
            structlog.processors.JSONRenderer(),
        ]
    else:
        # Console format for development
        processors = shared_processors + [
            structlog.dev.ConsoleRenderer(colors=True),
        ]

    structlog.configure(
        processors=processors,
        wrapper_class=structlog.make_filtering_bound_logger(
            getattr(logging, log_level.upper())
        ),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )


def get_logger(name: str) -> structlog.BoundLogger:
    """Get a logger instance."""
    return structlog.get_logger(name)
```

---

### Step 4: Pydantic Schemas

```python
# src/rag/api/schemas/common.py
"""Common schema definitions."""
from pydantic import BaseModel, Field
from typing import Any
from datetime import datetime


class ErrorResponse(BaseModel):
    """Standard error response."""
    error: str
    message: str
    details: dict[str, Any] = Field(default_factory=dict)
    timestamp: datetime = Field(default_factory=datetime.now)


class SuccessResponse(BaseModel):
    """Standard success response."""
    success: bool = True
    message: str
    data: dict[str, Any] = Field(default_factory=dict)
```

```python
# src/rag/api/schemas/documents.py
"""Document-related schemas."""
from pydantic import BaseModel, Field, field_validator
from typing import Optional
from datetime import datetime


class DocumentMetadata(BaseModel):
    """Document metadata."""
    filename: str
    file_type: str
    file_size: int
    chunk_count: int = 0
    created_at: datetime = Field(default_factory=datetime.now)


class DocumentResponse(BaseModel):
    """Response for a single document."""
    id: str
    source: str
    metadata: DocumentMetadata


class DocumentListResponse(BaseModel):
    """Response for document list."""
    documents: list[DocumentResponse]
    total: int


class IngestRequest(BaseModel):
    """Request for document ingestion (JSON metadata)."""
    chunk_size: int = Field(default=512, ge=100, le=2000)
    chunk_overlap: int = Field(default=50, ge=0, le=200)

    @field_validator("chunk_overlap")
    @classmethod
    def validate_overlap(cls, v: int, info) -> int:
        chunk_size = info.data.get("chunk_size", 512)
        if v >= chunk_size:
            raise ValueError("chunk_overlap must be less than chunk_size")
        return v


class IngestResponse(BaseModel):
    """Response for document ingestion."""
    document_id: str
    filename: str
    chunks_created: int
    message: str
```

```python
# src/rag/api/schemas/query.py
"""Query-related schemas."""
from pydantic import BaseModel, Field, field_validator
from typing import Optional


class SourceCitation(BaseModel):
    """Source citation in response."""
    document_id: str
    filename: str
    content_preview: str = Field(..., max_length=500)
    relevance_score: float
    start_char: int
    end_char: int


class QueryRequest(BaseModel):
    """Request for querying the RAG system."""
    query: str = Field(..., min_length=1, max_length=1000)
    top_k: int = Field(default=5, ge=1, le=20)
    use_reranker: bool = False
    filter_document_id: Optional[str] = None

    @field_validator("query")
    @classmethod
    def validate_query(cls, v: str) -> str:
        v = v.strip()
        if not v:
            raise ValueError("Query cannot be empty or whitespace only")
        return v


class QueryResponse(BaseModel):
    """Response from RAG query."""
    answer: str
    query: str
    sources: list[SourceCitation]
    processing_time_ms: float
```

---

### Step 5: Service Layer

```python
# src/rag/services/base.py
"""Base service classes."""
from abc import ABC, abstractmethod
from typing import Any
from rag.logging_config import get_logger


class BaseService(ABC):
    """Abstract base class for services."""

    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)

    @abstractmethod
    def health_check(self) -> dict[str, Any]:
        """Check service health."""
        pass
```

```python
# src/rag/services/ingestion.py
"""Ingestion service."""
from pathlib import Path
from typing import BinaryIO
import tempfile
from tenacity import retry, stop_after_attempt, wait_exponential

from rag.services.base import BaseService
from rag.ingestion.loader import DocumentLoader
from rag.ingestion.chunker import SentenceChunker
from rag.embeddings.embedder import Embedder
from rag.vectorstore.qdrant import QdrantStore
from rag.exceptions import DocumentProcessingError, EmbeddingError, VectorStoreError
from rag.models import Document


class IngestionService(BaseService):
    """Service for document ingestion."""

    def __init__(
        self,
        loader: DocumentLoader = None,
        chunker: SentenceChunker = None,
        embedder: Embedder = None,
        store: QdrantStore = None,
    ):
        super().__init__()
        self.loader = loader or DocumentLoader()
        self.chunker = chunker or SentenceChunker()
        self.embedder = embedder or Embedder()
        self.store = store or QdrantStore()

    def health_check(self) -> dict:
        """Check ingestion service health."""
        return {
            "loader": "ok",
            "chunker": "ok",
            "embedder": self._check_embedder(),
            "store": self._check_store(),
        }

    def _check_embedder(self) -> str:
        try:
            self.embedder.embed(["test"])
            return "ok"
        except Exception as e:
            return f"error: {str(e)}"

    def _check_store(self) -> str:
        try:
            self.store.client.get_collections()
            return "ok"
        except Exception as e:
            return f"error: {str(e)}"

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
    )
    def ingest_file(
        self,
        file: BinaryIO,
        filename: str,
        chunk_size: int = 512,
        chunk_overlap: int = 50,
    ) -> tuple[str, int]:
        """
        Ingest a file into the RAG system.

        Returns:
            Tuple of (document_id, chunks_created)
        """
        self.logger.info("ingesting_file", filename=filename)

        # Save uploaded file temporarily
        suffix = Path(filename).suffix
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp.write(file.read())
            tmp_path = Path(tmp.name)

        try:
            # Load document
            document = self.loader.load(tmp_path)
            document.metadata["original_filename"] = filename
            self.logger.info("document_loaded", doc_id=document.id, chars=len(document.content))

            # Chunk document
            self.chunker.chunk_size = chunk_size
            self.chunker.overlap = chunk_overlap
            chunks = list(self.chunker.chunk(document))
            self.logger.info("document_chunked", doc_id=document.id, chunks=len(chunks))

            if not chunks:
                raise DocumentProcessingError(
                    "No chunks created from document",
                    {"filename": filename}
                )

            # Generate embeddings
            try:
                texts = [c.content for c in chunks]
                embeddings = self.embedder.embed(texts)
                for chunk, embedding in zip(chunks, embeddings):
                    chunk.embedding = embedding
            except Exception as e:
                raise EmbeddingError(
                    f"Failed to generate embeddings: {str(e)}",
                    {"filename": filename}
                )

            # Store in vector database
            try:
                self.store.upsert(chunks)
            except Exception as e:
                raise VectorStoreError(
                    f"Failed to store vectors: {str(e)}",
                    {"filename": filename}
                )

            self.logger.info(
                "ingestion_complete",
                doc_id=document.id,
                chunks=len(chunks),
                filename=filename
            )

            return document.id, len(chunks)

        finally:
            # Cleanup temp file
            tmp_path.unlink(missing_ok=True)

    def delete_document(self, document_id: str) -> bool:
        """Delete a document and its chunks from the store."""
        self.logger.info("deleting_document", doc_id=document_id)
        try:
            self.store.delete_by_document_id(document_id)
            return True
        except Exception as e:
            self.logger.error("delete_failed", doc_id=document_id, error=str(e))
            raise VectorStoreError(
                f"Failed to delete document: {str(e)}",
                {"document_id": document_id}
            )
```

```python
# src/rag/services/retrieval.py
"""Retrieval service."""
import time
from tenacity import retry, stop_after_attempt, wait_exponential

from rag.services.base import BaseService
from rag.embeddings.embedder import Embedder
from rag.vectorstore.qdrant import QdrantStore
from rag.retrieval.reranker import Reranker
from rag.llm.groq import GroqLLM
from rag.models import SearchResult, RAGResponse
from rag.exceptions import EmbeddingError, VectorStoreError, LLMError
from rag.config import settings


class RetrievalService(BaseService):
    """Service for retrieval and generation."""

    def __init__(
        self,
        embedder: Embedder = None,
        store: QdrantStore = None,
        reranker: Reranker = None,
        llm: GroqLLM = None,
    ):
        super().__init__()
        self.embedder = embedder or Embedder()
        self.store = store or QdrantStore()
        self.reranker = reranker
        self.llm = llm or GroqLLM()

    def health_check(self) -> dict:
        """Check retrieval service health."""
        return {
            "embedder": "ok",
            "store": self._check_store(),
            "llm": self._check_llm(),
        }

    def _check_store(self) -> str:
        try:
            self.store.client.get_collections()
            return "ok"
        except Exception as e:
            return f"error: {str(e)}"

    def _check_llm(self) -> str:
        # Just check if API key is configured
        return "ok" if settings.groq_api_key else "error: no API key"

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
    )
    def query(
        self,
        query: str,
        top_k: int = 5,
        use_reranker: bool = False,
        filter_document_id: str = None,
    ) -> tuple[RAGResponse, float]:
        """
        Query the RAG system.

        Returns:
            Tuple of (response, processing_time_ms)
        """
        start_time = time.time()
        self.logger.info("query_started", query=query[:50], top_k=top_k)

        # Embed query
        try:
            query_vector = self.embedder.embed_query(query)
        except Exception as e:
            raise EmbeddingError(f"Failed to embed query: {str(e)}")

        # Search vector store
        try:
            fetch_k = top_k * 2 if use_reranker else top_k
            results = self.store.search(
                query_vector,
                top_k=fetch_k,
                filter_doc_id=filter_document_id
            )
        except Exception as e:
            raise VectorStoreError(f"Search failed: {str(e)}")

        # Rerank if enabled
        if use_reranker and results:
            if self.reranker is None:
                self.reranker = Reranker()
            results = self.reranker.rerank(query, results, top_k=top_k)
        else:
            results = results[:top_k]

        # Convert to SearchResult
        search_results = [
            SearchResult(chunk=chunk, score=score)
            for chunk, score in results
        ]

        # Generate response
        try:
            response = self.llm.generate(query, search_results)
        except Exception as e:
            raise LLMError(f"LLM generation failed: {str(e)}")

        processing_time = (time.time() - start_time) * 1000
        self.logger.info(
            "query_complete",
            query=query[:50],
            sources=len(search_results),
            time_ms=processing_time
        )

        return response, processing_time
```

---

### Step 6: FastAPI Main Application

```python
# src/rag/api/main.py
"""FastAPI application."""
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import time

from rag.api.routes import documents, query, health
from rag.exceptions import RAGException
from rag.logging_config import setup_logging, get_logger
from rag.config import settings


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler."""
    # Startup
    setup_logging(json_format=True)
    logger = get_logger("api")
    logger.info("application_starting", version="0.2.0")

    yield

    # Shutdown
    logger.info("application_stopping")


app = FastAPI(
    title="RAG System API",
    description="REST API for Retrieval-Augmented Generation",
    version="0.2.0",
    lifespan=lifespan,
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Request timing middleware
@app.middleware("http")
async def add_timing_header(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    response.headers["X-Process-Time"] = f"{process_time:.3f}"
    return response


# Exception handlers
@app.exception_handler(RAGException)
async def rag_exception_handler(request: Request, exc: RAGException):
    logger = get_logger("api")
    logger.error(
        "rag_exception",
        error=exc.__class__.__name__,
        message=exc.message,
        details=exc.details,
        path=str(request.url),
    )
    return JSONResponse(
        status_code=400,
        content={
            "error": exc.__class__.__name__,
            "message": exc.message,
            "details": exc.details,
        },
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger = get_logger("api")
    logger.exception(
        "unhandled_exception",
        error=str(exc),
        path=str(request.url),
    )
    return JSONResponse(
        status_code=500,
        content={
            "error": "InternalServerError",
            "message": "An unexpected error occurred",
            "details": {},
        },
    )


# Include routers
app.include_router(health.router, prefix="/api/v1", tags=["Health"])
app.include_router(documents.router, prefix="/api/v1", tags=["Documents"])
app.include_router(query.router, prefix="/api/v1", tags=["Query"])


@app.get("/")
async def root():
    """Root endpoint."""
    return {
        "name": "RAG System API",
        "version": "0.2.0",
        "docs": "/docs",
    }
```

---

### Step 7: Document Endpoints

```python
# src/rag/api/routes/documents.py
"""Document management endpoints."""
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException
from typing import Annotated

from rag.api.schemas.documents import (
    IngestRequest,
    IngestResponse,
    DocumentListResponse,
    DocumentResponse,
)
from rag.api.dependencies import get_ingestion_service
from rag.services.ingestion import IngestionService
from rag.exceptions import DocumentNotFoundError


router = APIRouter(prefix="/documents")


@router.post("/ingest", response_model=IngestResponse)
async def ingest_document(
    file: Annotated[UploadFile, File(description="Document to ingest")],
    service: Annotated[IngestionService, Depends(get_ingestion_service)],
    chunk_size: int = 512,
    chunk_overlap: int = 50,
):
    """
    Upload and ingest a document into the RAG system.

    Supported formats: PDF, TXT, MD, DOCX
    """
    # Validate file type
    allowed_types = {".pdf", ".txt", ".md", ".docx"}
    filename = file.filename or "unknown"
    suffix = "." + filename.rsplit(".", 1)[-1].lower() if "." in filename else ""

    if suffix not in allowed_types:
        raise HTTPException(
            status_code=400,
            detail=f"Unsupported file type: {suffix}. Allowed: {allowed_types}"
        )

    # Ingest document
    doc_id, chunks_created = service.ingest_file(
        file=file.file,
        filename=filename,
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
    )

    return IngestResponse(
        document_id=doc_id,
        filename=filename,
        chunks_created=chunks_created,
        message=f"Successfully ingested {filename}",
    )


@router.get("", response_model=DocumentListResponse)
async def list_documents(
    service: Annotated[IngestionService, Depends(get_ingestion_service)],
    limit: int = 100,
    offset: int = 0,
):
    """List all ingested documents."""
    # Get unique document IDs from vector store
    documents = service.store.list_documents(limit=limit, offset=offset)

    return DocumentListResponse(
        documents=documents,
        total=len(documents),
    )


@router.get("/{document_id}", response_model=DocumentResponse)
async def get_document(
    document_id: str,
    service: Annotated[IngestionService, Depends(get_ingestion_service)],
):
    """Get details for a specific document."""
    document = service.store.get_document(document_id)

    if not document:
        raise DocumentNotFoundError(
            f"Document not found: {document_id}",
            {"document_id": document_id}
        )

    return document


@router.delete("/{document_id}")
async def delete_document(
    document_id: str,
    service: Annotated[IngestionService, Depends(get_ingestion_service)],
):
    """Delete a document and its chunks."""
    success = service.delete_document(document_id)

    return {
        "success": success,
        "message": f"Document {document_id} deleted",
    }
```

---

### Step 8: Query Endpoints

```python
# src/rag/api/routes/query.py
"""Query endpoints."""
from fastapi import APIRouter, Depends
from typing import Annotated

from rag.api.schemas.query import QueryRequest, QueryResponse, SourceCitation
from rag.api.dependencies import get_retrieval_service
from rag.services.retrieval import RetrievalService


router = APIRouter()


@router.post("/query", response_model=QueryResponse)
async def query_documents(
    request: QueryRequest,
    service: Annotated[RetrievalService, Depends(get_retrieval_service)],
):
    """
    Query the RAG system with a natural language question.

    Returns an AI-generated answer with source citations.
    """
    response, processing_time = service.query(
        query=request.query,
        top_k=request.top_k,
        use_reranker=request.use_reranker,
        filter_document_id=request.filter_document_id,
    )

    # Convert sources to citations
    citations = [
        SourceCitation(
            document_id=result.chunk.document_id,
            filename=result.chunk.metadata.get("filename", "Unknown"),
            content_preview=result.chunk.content[:500],
            relevance_score=result.score,
            start_char=result.chunk.start_char,
            end_char=result.chunk.end_char,
        )
        for result in response.sources
    ]

    return QueryResponse(
        answer=response.answer,
        query=response.query,
        sources=citations,
        processing_time_ms=processing_time,
    )
```

---

### Step 9: Health Check Endpoint

```python
# src/rag/api/routes/health.py
"""Health check endpoints."""
from fastapi import APIRouter, Depends
from typing import Annotated

from rag.api.dependencies import get_ingestion_service, get_retrieval_service
from rag.services.ingestion import IngestionService
from rag.services.retrieval import RetrievalService


router = APIRouter()


@router.get("/health")
async def health_check(
    ingestion: Annotated[IngestionService, Depends(get_ingestion_service)],
    retrieval: Annotated[RetrievalService, Depends(get_retrieval_service)],
):
    """
    Check the health of all system components.
    """
    ingestion_health = ingestion.health_check()
    retrieval_health = retrieval.health_check()

    # Determine overall status
    all_checks = {**ingestion_health, **retrieval_health}
    is_healthy = all(v == "ok" for v in all_checks.values())

    return {
        "status": "healthy" if is_healthy else "degraded",
        "components": {
            "ingestion": ingestion_health,
            "retrieval": retrieval_health,
        },
    }


@router.get("/health/live")
async def liveness():
    """Kubernetes liveness probe."""
    return {"status": "alive"}


@router.get("/health/ready")
async def readiness(
    ingestion: Annotated[IngestionService, Depends(get_ingestion_service)],
):
    """Kubernetes readiness probe."""
    try:
        # Check if we can connect to Qdrant
        ingestion.store.client.get_collections()
        return {"status": "ready"}
    except Exception:
        return {"status": "not_ready"}, 503
```

---

### Step 10: Dependencies

```python
# src/rag/api/dependencies.py
"""FastAPI dependency injection."""
from functools import lru_cache

from rag.services.ingestion import IngestionService
from rag.services.retrieval import RetrievalService
from rag.ingestion.loader import DocumentLoader
from rag.ingestion.chunker import SentenceChunker
from rag.embeddings.embedder import Embedder
from rag.vectorstore.qdrant import QdrantStore
from rag.llm.groq import GroqLLM


@lru_cache()
def get_embedder() -> Embedder:
    """Get cached embedder instance."""
    return Embedder()


@lru_cache()
def get_store() -> QdrantStore:
    """Get cached store instance."""
    return QdrantStore()


@lru_cache()
def get_llm() -> GroqLLM:
    """Get cached LLM instance."""
    return GroqLLM()


def get_ingestion_service() -> IngestionService:
    """Get ingestion service with shared dependencies."""
    return IngestionService(
        loader=DocumentLoader(),
        chunker=SentenceChunker(),
        embedder=get_embedder(),
        store=get_store(),
    )


def get_retrieval_service() -> RetrievalService:
    """Get retrieval service with shared dependencies."""
    return RetrievalService(
        embedder=get_embedder(),
        store=get_store(),
        llm=get_llm(),
    )
```

---

### Step 11: Update Qdrant Store (add missing methods)

```python
# Add to src/rag/vectorstore/qdrant.py

def list_documents(self, limit: int = 100, offset: int = 0) -> list[dict]:
    """List unique documents in the collection."""
    # Scroll through points to get unique document IDs
    points, _ = self.client.scroll(
        collection_name=self.collection_name,
        limit=limit,
        offset=offset,
        with_payload=True,
        with_vectors=False,
    )

    # Group by document_id
    docs = {}
    for point in points:
        doc_id = point.payload.get("document_id")
        if doc_id and doc_id not in docs:
            docs[doc_id] = {
                "id": doc_id,
                "source": point.payload.get("metadata", {}).get("filename", "Unknown"),
                "metadata": point.payload.get("metadata", {}),
            }

    return list(docs.values())


def get_document(self, document_id: str) -> dict | None:
    """Get document info by ID."""
    results = self.client.scroll(
        collection_name=self.collection_name,
        scroll_filter=Filter(
            must=[FieldCondition(
                key="document_id",
                match=MatchValue(value=document_id)
            )]
        ),
        limit=1,
        with_payload=True,
        with_vectors=False,
    )

    points, _ = results
    if not points:
        return None

    point = points[0]
    return {
        "id": document_id,
        "source": point.payload.get("metadata", {}).get("filename", "Unknown"),
        "metadata": point.payload.get("metadata", {}),
    }


def delete_by_document_id(self, document_id: str) -> None:
    """Delete all chunks for a document."""
    self.client.delete(
        collection_name=self.collection_name,
        points_selector=Filter(
            must=[FieldCondition(
                key="document_id",
                match=MatchValue(value=document_id)
            )]
        ),
    )
```

---

### Step 12: Unit Tests

```python
# tests/conftest.py
"""Shared test fixtures."""
import pytest
from unittest.mock import Mock, MagicMock
from rag.models import Document, Chunk, SearchResult


@pytest.fixture
def sample_document():
    """Create a sample document."""
    return Document(
        id="doc123",
        content="This is a test document. It has multiple sentences. Each sentence is important.",
        source="/path/to/test.txt",
        metadata={"filename": "test.txt", "type": ".txt"}
    )


@pytest.fixture
def sample_chunks(sample_document):
    """Create sample chunks."""
    return [
        Chunk(
            id="chunk1",
            document_id=sample_document.id,
            content="This is a test document.",
            embedding=[0.1] * 768,
            start_char=0,
            end_char=25,
            metadata=sample_document.metadata,
        ),
        Chunk(
            id="chunk2",
            document_id=sample_document.id,
            content="It has multiple sentences.",
            embedding=[0.2] * 768,
            start_char=26,
            end_char=52,
            metadata=sample_document.metadata,
        ),
    ]


@pytest.fixture
def mock_embedder():
    """Mock embedder."""
    embedder = Mock()
    embedder.embed.return_value = [[0.1] * 768]
    embedder.embed_query.return_value = [0.1] * 768
    return embedder


@pytest.fixture
def mock_store():
    """Mock Qdrant store."""
    store = Mock()
    store.client = Mock()
    store.client.get_collections.return_value = Mock(collections=[])
    store.search.return_value = []
    store.upsert.return_value = None
    return store


@pytest.fixture
def mock_llm():
    """Mock LLM."""
    from rag.models import RAGResponse
    llm = Mock()
    llm.generate.return_value = RAGResponse(
        answer="This is a test answer.",
        sources=[],
        query="test query"
    )
    return llm
```

```python
# tests/unit/test_chunker.py
"""Tests for the chunker module."""
import pytest
from rag.ingestion.chunker import SentenceChunker


class TestSentenceChunker:

    def test_chunk_basic(self, sample_document):
        """Test basic chunking."""
        chunker = SentenceChunker(chunk_size=50, overlap=10)
        chunks = list(chunker.chunk(sample_document))

        assert len(chunks) > 0
        assert all(chunk.document_id == sample_document.id for chunk in chunks)

    def test_chunk_size_respected(self, sample_document):
        """Test that chunks don't exceed size limit (approximately)."""
        chunker = SentenceChunker(chunk_size=30, overlap=5)
        chunks = list(chunker.chunk(sample_document))

        # Chunks should be close to chunk_size (may exceed slightly due to sentence boundaries)
        for chunk in chunks:
            assert len(chunk.content) <= 100  # Allow some overflow

    def test_empty_document(self):
        """Test chunking empty document."""
        from rag.models import Document
        doc = Document(id="empty", content="", source="empty.txt")
        chunker = SentenceChunker()
        chunks = list(chunker.chunk(doc))

        assert len(chunks) == 0
```

```python
# tests/unit/test_services.py
"""Tests for service layer."""
import pytest
from unittest.mock import Mock, patch, MagicMock
from io import BytesIO

from rag.services.ingestion import IngestionService
from rag.services.retrieval import RetrievalService
from rag.exceptions import DocumentProcessingError


class TestIngestionService:

    def test_ingest_file_success(self, mock_embedder, mock_store):
        """Test successful file ingestion."""
        service = IngestionService(
            loader=Mock(),
            chunker=Mock(),
            embedder=mock_embedder,
            store=mock_store,
        )

        # Setup mocks
        from rag.models import Document, Chunk
        mock_doc = Document(id="test123", content="Test content", source="test.txt")
        service.loader.load.return_value = mock_doc

        mock_chunks = [Chunk(id="c1", document_id="test123", content="Test")]
        service.chunker.chunk.return_value = iter(mock_chunks)

        # Create test file
        file = BytesIO(b"Test content")

        with patch("tempfile.NamedTemporaryFile"):
            with patch("pathlib.Path"):
                doc_id, chunks = service.ingest_file(file, "test.txt")

        assert doc_id == "test123"
        assert mock_store.upsert.called

    def test_health_check(self, mock_embedder, mock_store):
        """Test health check."""
        service = IngestionService(
            embedder=mock_embedder,
            store=mock_store,
        )

        health = service.health_check()

        assert "loader" in health
        assert "embedder" in health
        assert "store" in health


class TestRetrievalService:

    def test_query_success(self, mock_embedder, mock_store, mock_llm, sample_chunks):
        """Test successful query."""
        service = RetrievalService(
            embedder=mock_embedder,
            store=mock_store,
            llm=mock_llm,
        )

        # Setup mock return
        mock_store.search.return_value = [(sample_chunks[0], 0.9)]

        response, time_ms = service.query("What is this?")

        assert response.answer == "This is a test answer."
        assert time_ms > 0
        assert mock_embedder.embed_query.called
        assert mock_store.search.called
        assert mock_llm.generate.called
```

```python
# tests/integration/test_api_query.py
"""Integration tests for query API."""
import pytest
from fastapi.testclient import TestClient
from unittest.mock import patch, Mock

from rag.api.main import app
from rag.models import RAGResponse, SearchResult, Chunk


@pytest.fixture
def client():
    """Create test client."""
    return TestClient(app)


class TestQueryEndpoint:

    def test_query_success(self, client):
        """Test successful query."""
        # Mock the retrieval service
        mock_response = RAGResponse(
            answer="Paris is the capital of France.",
            sources=[
                SearchResult(
                    chunk=Chunk(
                        id="c1",
                        document_id="doc1",
                        content="Paris is the capital...",
                        start_char=0,
                        end_char=50,
                        metadata={"filename": "geo.txt"}
                    ),
                    score=0.95
                )
            ],
            query="What is the capital of France?"
        )

        with patch("rag.api.dependencies.get_retrieval_service") as mock:
            service = Mock()
            service.query.return_value = (mock_response, 150.0)
            mock.return_value = service

            response = client.post(
                "/api/v1/query",
                json={"query": "What is the capital of France?"}
            )

        assert response.status_code == 200
        data = response.json()
        assert "answer" in data
        assert "sources" in data
        assert len(data["sources"]) == 1

    def test_query_empty_query(self, client):
        """Test query with empty string."""
        response = client.post(
            "/api/v1/query",
            json={"query": ""}
        )

        assert response.status_code == 422  # Validation error

    def test_query_with_reranker(self, client):
        """Test query with reranker enabled."""
        with patch("rag.api.dependencies.get_retrieval_service") as mock:
            service = Mock()
            service.query.return_value = (
                RAGResponse(answer="Test", sources=[], query="test"),
                100.0
            )
            mock.return_value = service

            response = client.post(
                "/api/v1/query",
                json={
                    "query": "test query",
                    "use_reranker": True,
                    "top_k": 3
                }
            )

        assert response.status_code == 200
        service.query.assert_called_once()
        call_args = service.query.call_args
        assert call_args.kwargs.get("use_reranker") is True
```

---

### Step 13: Docker Setup

```dockerfile
# Dockerfile
FROM python:3.11-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install uv for faster package installation
RUN pip install uv

# Copy project files
COPY pyproject.toml .
COPY src/ src/

# Install dependencies
RUN uv pip install --system -e ".[dev]"

# Production stage
FROM python:3.11-slim

WORKDIR /app

# Copy installed packages from builder
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# Copy application code
COPY src/ src/

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/api/v1/health/live || exit 1

# Run the application
CMD ["uvicorn", "rag.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```yaml
# docker-compose.yml
version: "3.8"

services:
  rag-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - LOG_LEVEL=INFO
    depends_on:
      qdrant:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./data:/app/data

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

volumes:
  qdrant_data:
```

---

## Running Phase 2

### Development Mode

```bash
# Start Qdrant
docker run -d --name qdrant -p 6333:6333 -p 6334:6334 qdrant/qdrant

# Run API in development mode
uvicorn rag.api.main:app --reload --port 8000

# Access docs at http://localhost:8000/docs
```

### Docker Compose

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f rag-api

# Stop services
docker-compose down
```

### API Usage Examples

```bash
# Ingest a document
curl -X POST "http://localhost:8000/api/v1/documents/ingest" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@document.pdf" \
  -F "chunk_size=512"

# Query the system
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is the main topic?", "top_k": 5}'

# Health check
curl http://localhost:8000/api/v1/health

# List documents
curl http://localhost:8000/api/v1/documents
```

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=rag --cov-report=html

# Run only unit tests
pytest tests/unit/ -v

# Run only integration tests
pytest tests/integration/ -v
```

---

## Milestone Checklist

- [ ] New dependencies added (FastAPI, structlog, tenacity, pytest)
- [ ] Custom exceptions implemented
- [ ] Structured logging configured
- [ ] Pydantic schemas for request/response
- [ ] Service layer with dependency injection
- [ ] FastAPI application with middleware
- [ ] Document endpoints (ingest, list, get, delete)
- [ ] Query endpoint with citations
- [ ] Health check endpoints
- [ ] Retry decorators on external calls
- [ ] Unit tests with >70% coverage
- [ ] Integration tests for API endpoints
- [ ] Docker + docker-compose working
- [ ] API documentation accessible at /docs

---

## Next Steps

After completing Phase 2:

1. **Phase 3**: Add PostgreSQL for metadata, multi-tenancy, async processing
2. **Phase 4**: Add Kong API gateway, authentication, advanced RAG techniques

---

**Ready to start?** Begin with Step 1: Add New Dependencies!
