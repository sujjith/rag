{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2.1: Logging Artifacts (Files) with MLflow\n",
    "\n",
    "This comprehensive notebook demonstrates:\n",
    "1. **Logging Plots** - Save matplotlib visualizations\n",
    "2. **Logging CSV Files** - Store data files\n",
    "3. **Logging JSON Configs** - Save configuration files\n",
    "4. **Logging Directories** - Store multiple files at once\n",
    "5. **Logging Binary Files** - Save pickle files\n",
    "\n",
    "## What are Artifacts?\n",
    "\n",
    "**Artifacts** are any files you want to save alongside your ML experiment. Think of them as \"attachments\" to your experiment run. Common examples include:\n",
    "- Plots and visualizations (PNG, PDF)\n",
    "- Data files (CSV, JSON)\n",
    "- Model files (pickle, joblib)\n",
    "- Configuration files\n",
    "- Text reports and notes\n",
    "\n",
    "## Learning Goals\n",
    "- Understand what artifacts are and why they matter\n",
    "- Learn to log different file types to MLflow\n",
    "- Know the difference between `log_artifact()` and `log_artifacts()`\n",
    "- View artifacts in the MLflow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "Let's import all the libraries we need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow: The main library for experiment tracking\n",
    "import mlflow\n",
    "\n",
    "# matplotlib: For creating plots and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pandas: For creating and manipulating data tables (DataFrames)\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: For numerical operations and random number generation\n",
    "import numpy as np\n",
    "\n",
    "# json: For creating and saving JSON configuration files\n",
    "import json\n",
    "\n",
    "# os: For file and directory operations\n",
    "import os\n",
    "\n",
    "# shutil: For cleaning up directories\n",
    "import shutil\n",
    "\n",
    "# pickle: For saving Python objects as binary files\n",
    "import pickle\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to learn about artifact logging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to MLflow\n",
    "\n",
    "Before we can log anything, we need to connect to our MLflow tracking server and set up an experiment.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Tracking URI**: The address where MLflow server is running\n",
    "- **Experiment**: A named collection of runs (like a folder for related experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MLflow tracking server URL from environment variable\n",
    "# If not set, default to localhost:5000\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "\n",
    "# Tell MLflow where to send the tracking data\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Create or select an experiment to log our runs\n",
    "# If the experiment doesn't exist, MLflow creates it automatically\n",
    "mlflow.set_experiment(\"phase2-artifacts\")\n",
    "\n",
    "print(f\"Connected to MLflow at: {TRACKING_URI}\")\n",
    "print(f\"Experiment: phase2-artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Temporary Directory for Artifacts\n",
    "\n",
    "Before logging artifacts to MLflow, we first need to create them as files on our local disk. MLflow will then upload these files to its artifact storage.\n",
    "\n",
    "**Why a temporary directory?**\n",
    "- Keeps our workspace organized\n",
    "- Makes cleanup easier after logging\n",
    "- Prevents cluttering the main project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name for our temporary directory\n",
    "TEMP_DIR = \"temp_artifacts\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "# exist_ok=True means: don't raise an error if it already exists\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Created temporary directory: {TEMP_DIR}/\")\n",
    "print(\"This is where we'll save files before logging to MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Start an MLflow Run and Log Artifacts\n",
    "\n",
    "Now let's start an MLflow run and log different types of artifacts. We'll use the `with` statement to ensure the run is properly closed even if errors occur.\n",
    "\n",
    "**Key Functions:**\n",
    "- `mlflow.start_run()`: Begins a new experiment run\n",
    "- `mlflow.log_artifact(path)`: Logs a single file\n",
    "- `mlflow.log_artifacts(dir)`: Logs all files in a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Log a Matplotlib Plot\n",
    "\n",
    "Plots are one of the most common artifacts. They help you visualize model performance, data distributions, feature importance, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an MLflow run to group all our artifacts together\n",
    "# run_name helps you identify this run in the UI\n",
    "mlflow.start_run(run_name=\"artifact-demo\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"[1] Creating and Logging a Plot\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a figure with 2 subplots side by side\n",
    "# figsize=(12, 5) means 12 inches wide, 5 inches tall\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ---- Left Plot: Line Chart ----\n",
    "# Create 100 evenly spaced points from 0 to 10\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# Plot sine and cosine waves\n",
    "axes[0].plot(x, np.sin(x), label=\"sin(x)\", color='blue')\n",
    "axes[0].plot(x, np.cos(x), label=\"cos(x)\", color='red')\n",
    "axes[0].set_title(\"Trigonometric Functions\")\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].legend()  # Show the legend with labels\n",
    "axes[0].grid(True)  # Add a grid for better readability\n",
    "\n",
    "# ---- Right Plot: Scatter Chart ----\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a scatter plot with random data\n",
    "# c=... colors each point based on a third random value\n",
    "# cmap='viridis' uses a nice color gradient\n",
    "scatter = axes[1].scatter(\n",
    "    np.random.randn(100),  # 100 random x values\n",
    "    np.random.randn(100),  # 100 random y values\n",
    "    c=np.random.randn(100),  # Color based on random values\n",
    "    cmap='viridis'\n",
    ")\n",
    "axes[1].set_title(\"Random Scatter Plot\")\n",
    "axes[1].set_xlabel(\"Feature 1\")\n",
    "axes[1].set_ylabel(\"Feature 2\")\n",
    "plt.colorbar(scatter, ax=axes[1], label=\"Value\")\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot to a file\n",
    "plot_path = f\"{TEMP_DIR}/analysis_plot.png\"\n",
    "fig.savefig(plot_path, dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()  # Display in notebook\n",
    "plt.close()  # Close to free memory\n",
    "\n",
    "# Log the plot file to MLflow\n",
    "mlflow.log_artifact(plot_path)\n",
    "\n",
    "print(f\"\\nLogged: analysis_plot.png\")\n",
    "print(\"This plot will appear in the 'Artifacts' tab of your MLflow run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Log a CSV Data File\n",
    "\n",
    "CSV files are useful for logging:\n",
    "- Training data samples\n",
    "- Prediction results\n",
    "- Feature importance rankings\n",
    "- Any tabular data you want to preserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[2] Creating and Logging a CSV File\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a sample DataFrame with random data\n",
    "# This simulates a dataset with 3 features and 1 target variable\n",
    "df = pd.DataFrame({\n",
    "    \"feature_1\": np.random.randn(100),  # 100 random values from normal distribution\n",
    "    \"feature_2\": np.random.randn(100),\n",
    "    \"feature_3\": np.random.randn(100),\n",
    "    \"target\": np.random.choice([0, 1, 2], 100)  # Random class labels (0, 1, or 2)\n",
    "})\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nSample data (first 5 rows):\")\n",
    "print(df.head())\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "csv_path = f\"{TEMP_DIR}/sample_data.csv\"\n",
    "df.to_csv(csv_path, index=False)  # index=False: don't save row numbers\n",
    "\n",
    "# Log the CSV file to MLflow\n",
    "mlflow.log_artifact(csv_path)\n",
    "\n",
    "print(f\"\\nLogged: sample_data.csv ({len(df)} rows, {len(df.columns)} columns)\")\n",
    "print(\"You can download this file from the MLflow UI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Log a JSON Configuration File\n",
    "\n",
    "JSON files are perfect for saving:\n",
    "- Model configurations\n",
    "- Preprocessing settings\n",
    "- Experiment parameters\n",
    "- Any structured configuration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[3] Creating and Logging a JSON Config\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a configuration dictionary\n",
    "# This is a nested structure with model, preprocessing, and training settings\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"type\": \"RandomForest\",\n",
    "        \"n_estimators\": 100,  # Number of trees in the forest\n",
    "        \"max_depth\": 10       # Maximum depth of each tree\n",
    "    },\n",
    "    \"preprocessing\": {\n",
    "        \"normalize\": True,\n",
    "        \"handle_missing\": \"mean\",  # How to handle missing values\n",
    "        \"features\": [\"feature_1\", \"feature_2\", \"feature_3\"]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"test_size\": 0.2,      # 20% of data for testing\n",
    "        \"random_state\": 42,   # Seed for reproducibility\n",
    "        \"cv_folds\": 5         # Number of cross-validation folds\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display the config\n",
    "print(\"\\nConfiguration:\")\n",
    "print(json.dumps(config, indent=2))  # Pretty print the JSON\n",
    "\n",
    "# Save config to JSON file\n",
    "json_path = f\"{TEMP_DIR}/config.json\"\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(config, f, indent=2)  # indent=2 makes it human-readable\n",
    "\n",
    "# Log the JSON file to MLflow\n",
    "mlflow.log_artifact(json_path)\n",
    "\n",
    "print(f\"\\nLogged: config.json\")\n",
    "print(\"This preserves your exact experiment configuration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Log a Text File with Notes\n",
    "\n",
    "Text files are useful for:\n",
    "- Experiment notes and observations\n",
    "- README files\n",
    "- Log files\n",
    "- Any plain text documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[4] Creating and Logging Text Notes\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a text file with experiment notes\n",
    "notes_path = f\"{TEMP_DIR}/experiment_notes.txt\"\n",
    "\n",
    "# Open file in write mode and add content\n",
    "with open(notes_path, \"w\") as f:\n",
    "    f.write(\"Experiment Notes\\n\")\n",
    "    f.write(\"=\" * 40 + \"\\n\\n\")\n",
    "    f.write(\"Date: 2024-01-15\\n\")\n",
    "    f.write(\"Author: Data Science Team\\n\\n\")\n",
    "    f.write(\"Observations:\\n\")\n",
    "    f.write(\"- Model converged after 50 epochs\\n\")\n",
    "    f.write(\"- Feature 2 shows high importance\\n\")\n",
    "    f.write(\"- No overfitting detected\\n\\n\")\n",
    "    f.write(\"Next Steps:\\n\")\n",
    "    f.write(\"- Try different hyperparameters\\n\")\n",
    "    f.write(\"- Add more features\\n\")\n",
    "\n",
    "# Read and display the notes\n",
    "with open(notes_path, \"r\") as f:\n",
    "    print(\"\\nNotes content:\")\n",
    "    print(f.read())\n",
    "\n",
    "# Log the text file to MLflow\n",
    "mlflow.log_artifact(notes_path)\n",
    "\n",
    "print(f\"Logged: experiment_notes.txt\")\n",
    "print(\"Great for documenting your experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Log Multiple Files in a Directory\n",
    "\n",
    "Sometimes you want to log multiple related files together. Use `mlflow.log_artifacts()` (note the plural 's') to log an entire directory.\n",
    "\n",
    "**Difference:**\n",
    "- `log_artifact(path)` - Logs a single file\n",
    "- `log_artifacts(dir, artifact_path)` - Logs all files in a directory to a subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[5] Creating and Logging a Directory\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a subdirectory for reports\n",
    "reports_dir = f\"{TEMP_DIR}/reports\"\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "# Create 3 report files\n",
    "print(\"\\nCreating report files:\")\n",
    "for i in range(3):\n",
    "    report_path = f\"{reports_dir}/report_{i+1}.txt\"\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(f\"Report {i+1}\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"Accuracy: {0.85 + i*0.03:.2f}\\n\")  # Simulated accuracy\n",
    "        f.write(f\"Loss: {0.15 - i*0.02:.2f}\\n\")       # Simulated loss\n",
    "    print(f\"  - Created: report_{i+1}.txt\")\n",
    "\n",
    "# Log all files in the directory at once\n",
    "# artifact_path=\"reports\" creates a subfolder in MLflow artifacts\n",
    "mlflow.log_artifacts(reports_dir, artifact_path=\"reports\")\n",
    "\n",
    "print(f\"\\nLogged: reports/ directory (3 files)\")\n",
    "print(\"All files will appear under 'reports/' folder in MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Log a Binary (Pickle) File\n",
    "\n",
    "Pickle files are used to save Python objects (like model weights, preprocessors, or any Python data structure) in binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[6] Creating and Logging a Pickle File\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create sample model data (simulating model weights)\n",
    "model_data = {\n",
    "    \"weights\": np.random.randn(10, 5),  # 10x5 matrix of weights\n",
    "    \"bias\": np.random.randn(5)           # 5 bias values\n",
    "}\n",
    "\n",
    "print(f\"\\nModel weights shape: {model_data['weights'].shape}\")\n",
    "print(f\"Bias shape: {model_data['bias'].shape}\")\n",
    "\n",
    "# Save to pickle file\n",
    "pickle_path = f\"{TEMP_DIR}/model_weights.pkl\"\n",
    "with open(pickle_path, \"wb\") as f:  # \"wb\" = write binary\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "# Log the pickle file to MLflow\n",
    "mlflow.log_artifact(pickle_path)\n",
    "\n",
    "print(f\"\\nLogged: model_weights.pkl\")\n",
    "print(\"Binary files preserve exact Python objects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Log Some Metrics and End the Run\n",
    "\n",
    "Let's also log a metric and parameter to complete our run, then end it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[7] Logging Metrics and Ending Run\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Log a sample metric (numerical performance value)\n",
    "mlflow.log_metric(\"accuracy\", 0.92)\n",
    "print(\"Logged metric: accuracy = 0.92\")\n",
    "\n",
    "# Log a parameter (configuration value)\n",
    "mlflow.log_param(\"experiment_type\", \"artifact_demo\")\n",
    "print(\"Logged param: experiment_type = artifact_demo\")\n",
    "\n",
    "# End the run\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"\\nMLflow run completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Clean Up Temporary Files\n",
    "\n",
    "Now that all artifacts are safely stored in MLflow, we can clean up our temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the temporary directory and all its contents\n",
    "shutil.rmtree(TEMP_DIR)\n",
    "\n",
    "print(f\"Cleaned up: {TEMP_DIR}/ directory removed\")\n",
    "print(\"\\nAll artifacts are now safely stored in MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Artifact Types and When to Use Them\n",
    "\n",
    "| Artifact Type | File Extension | Use Case |\n",
    "|--------------|----------------|----------|\n",
    "| **Plots** | .png, .pdf | Visualizations, charts, graphs |\n",
    "| **CSV** | .csv | Data tables, predictions, feature rankings |\n",
    "| **JSON** | .json | Configurations, settings, structured data |\n",
    "| **Text** | .txt | Notes, logs, documentation |\n",
    "| **Pickle** | .pkl | Python objects, model weights |\n",
    "| **Directories** | folder/ | Multiple related files |\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "```python\n",
    "# Log a single file\n",
    "mlflow.log_artifact(\"path/to/file.png\")\n",
    "\n",
    "# Log all files in a directory\n",
    "mlflow.log_artifacts(\"path/to/dir\", artifact_path=\"subfolder_name\")\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "1. Open MLflow UI and find the 'artifact-demo' run\n",
    "2. Click on the 'Artifacts' tab to view all logged files\n",
    "3. Try downloading some artifacts to verify they're stored correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Artifact Logging Tutorial Complete!\")\n",
    "print(f\"\\nView all experiments: {TRACKING_URI}\")\n",
    "print(\"\\nWhat you learned:\")\n",
    "print(\"  1. How to log plots (.png)\")\n",
    "print(\"  2. How to log data files (.csv)\")\n",
    "print(\"  3. How to log configurations (.json)\")\n",
    "print(\"  4. How to log text notes (.txt)\")\n",
    "print(\"  5. How to log directories (multiple files)\")\n",
    "print(\"  6. How to log binary files (.pkl)\")\n",
    "print(\"\\nClick on the run and go to 'Artifacts' tab to see all files!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
