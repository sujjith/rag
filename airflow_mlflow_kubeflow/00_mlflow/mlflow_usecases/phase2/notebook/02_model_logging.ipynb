{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2.2: Logging and Loading ML Models with MLflow\n",
    "\n",
    "This comprehensive notebook demonstrates:\n",
    "1. **Training an ML Model** - Build a RandomForest classifier\n",
    "2. **Logging Models** - Save models to MLflow with metadata\n",
    "3. **Model Signatures** - Define input/output schemas\n",
    "4. **Input Examples** - Store sample inputs with your model\n",
    "5. **Loading Models** - Retrieve models for predictions\n",
    "\n",
    "## What is Model Logging?\n",
    "\n",
    "**Model logging** saves your trained model to MLflow so you can:\n",
    "- **Reproduce** results later by loading the exact same model\n",
    "- **Deploy** models to production\n",
    "- **Compare** different model versions\n",
    "- **Share** models with your team\n",
    "\n",
    "## Learning Goals\n",
    "- Understand how to log sklearn models to MLflow\n",
    "- Learn about model signatures and why they matter\n",
    "- Know how to load models back for predictions\n",
    "- Use both `sklearn` and `pyfunc` interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "We'll use MLflow for experiment tracking and sklearn for building our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Ready to learn about model logging!\n"
     ]
    }
   ],
   "source": [
    "# mlflow: Main library for experiment tracking\n",
    "import mlflow\n",
    "\n",
    "# mlflow.sklearn: Special module for logging sklearn models\n",
    "# This provides optimized functions for sklearn model serialization\n",
    "import mlflow.sklearn\n",
    "\n",
    "# sklearn.datasets: Contains built-in datasets for practice\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# sklearn.model_selection: Tools for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn.ensemble: Contains RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# sklearn.metrics: Functions to evaluate model performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# pandas: For working with tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# os: For environment variables\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to learn about model logging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to MLflow\n",
    "\n",
    "Connect to the MLflow tracking server and set up our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MLflow at: http://localhost:5000\n",
      "Experiment: phase2-model-logging\n"
     ]
    }
   ],
   "source": [
    "# Get the MLflow tracking server URL\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "\n",
    "# Tell MLflow where to send tracking data\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Create or select an experiment\n",
    "mlflow.set_experiment(\"phase2-model-logging\")\n",
    "\n",
    "print(f\"Connected to MLflow at: {TRACKING_URI}\")\n",
    "print(f\"Experiment: phase2-model-logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Explore the Dataset\n",
    "\n",
    "We'll use the classic **Iris dataset** - a simple dataset for classification that contains measurements of iris flowers.\n",
    "\n",
    "**Why use pandas DataFrame?**\n",
    "- Preserves feature names (important for signatures)\n",
    "- Better compatibility with MLflow\n",
    "- Easier to inspect and work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset Information\n",
      "============================================================\n",
      "\n",
      "Dataset: Iris\n",
      "Total samples: 150\n",
      "\n",
      "Features (measurements):\n",
      "  1. sepal length (cm)\n",
      "  2. sepal width (cm)\n",
      "  3. petal length (cm)\n",
      "  4. petal width (cm)\n",
      "\n",
      "Classes (flower types):\n",
      "  0: setosa\n",
      "  1: versicolor\n",
      "  2: virginica\n",
      "\n",
      "First 5 samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Iris dataset from sklearn\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a pandas DataFrame with feature names as column headers\n",
    "# This is better than using raw numpy arrays because:\n",
    "# 1. Column names are preserved\n",
    "# 2. MLflow can infer better signatures\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Target variable (what we're trying to predict)\n",
    "y = iris.target\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Dataset Information\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: Iris\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"\\nFeatures (measurements):\")\n",
    "for i, name in enumerate(iris.feature_names, 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "print(f\"\\nClasses (flower types):\")\n",
    "for i, name in enumerate(iris.target_names):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(f\"\\nFirst 5 samples:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split Data into Train and Test Sets\n",
    "\n",
    "We split the data to:\n",
    "- **Train** the model on 80% of the data\n",
    "- **Test** the model on the remaining 20% (unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete!\n",
      "Training samples: 120 (80%)\n",
      "Testing samples: 30 (20%)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "# test_size=0.2 means 20% for testing\n",
    "# random_state=42 ensures reproducibility (same split every time)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Data split complete!\")\n",
    "print(f\"Training samples: {len(X_train)} (80%)\")\n",
    "print(f\"Testing samples: {len(X_test)} (20%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model and Log to MLflow\n",
    "\n",
    "Now let's train a RandomForest model and log everything to MLflow.\n",
    "\n",
    "**What gets logged:**\n",
    "1. Parameters (hyperparameters like n_estimators, max_depth)\n",
    "2. Metrics (performance scores like accuracy)\n",
    "3. Model (the trained model itself)\n",
    "4. Signature (input/output schema)\n",
    "5. Input example (sample input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training and Logging Model\n",
      "============================================================\n",
      "\n",
      "[1] Training model...\n",
      "    Accuracy: 1.0000 (100.0% correct)\n",
      "\n",
      "[2] Logging parameters...\n",
      "    Logged: n_estimators=100, max_depth=5\n",
      "\n",
      "[3] Logging metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 22:08:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Logged: accuracy=1.0000\n",
      "\n",
      "[4] Creating model signature...\n",
      "    Input schema: ['sepal length (cm)': double (required), 'sepal width (cm)': double (required), 'petal length (cm)': double (required), 'petal width (cm)': double (required)]\n",
      "    Output schema: [Tensor('int64', (-1,))]\n",
      "\n",
      "[5] Logging model with signature and input example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 22:08:41 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model logged successfully!\n",
      "    Run ID: 807891a10ae5460e8bf7ab7a83e840d6\n",
      "üèÉ View run model-logging-demo at: http://localhost:5000/#/experiments/14/runs/807891a10ae5460e8bf7ab7a83e840d6\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/14\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Training and Logging Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start an MLflow run - all logs will be grouped under this run\n",
    "with mlflow.start_run(run_name=\"model-logging-demo\") as run:\n",
    "    \n",
    "    # ===== STEP 1: Train the Model =====\n",
    "    print(\"\\n[1] Training model...\")\n",
    "    \n",
    "    # Create a RandomForest classifier\n",
    "    # - n_estimators: Number of trees in the forest (more trees = better but slower)\n",
    "    # - max_depth: How deep each tree can grow (prevents overfitting)\n",
    "    # - random_state: Ensures reproducibility\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,  # Use 100 decision trees\n",
    "        max_depth=5,       # Limit tree depth to 5 levels\n",
    "        random_state=42    # For reproducibility\n",
    "    )\n",
    "    \n",
    "    # Train the model on training data\n",
    "    # The model learns patterns from X_train to predict y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ===== STEP 2: Evaluate the Model =====\n",
    "    # Use the trained model to predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy: percentage of correct predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"    Accuracy: {accuracy:.4f} ({accuracy*100:.1f}% correct)\")\n",
    "    \n",
    "    # ===== STEP 3: Log Parameters =====\n",
    "    # Parameters are the configuration settings you chose\n",
    "    print(\"\\n[2] Logging parameters...\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 5)\n",
    "    print(\"    Logged: n_estimators=100, max_depth=5\")\n",
    "    \n",
    "    # ===== STEP 4: Log Metrics =====\n",
    "    # Metrics are numerical performance measurements\n",
    "    print(\"\\n[3] Logging metrics...\")\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    print(f\"    Logged: accuracy={accuracy:.4f}\")\n",
    "    \n",
    "    # ===== STEP 5: Create Model Signature =====\n",
    "    print(\"\\n[4] Creating model signature...\")\n",
    "    \n",
    "    # Signature describes what the model expects as input and produces as output\n",
    "    # This is crucial for:\n",
    "    # - Model validation when loading\n",
    "    # - Automatic type checking in production\n",
    "    # - Documentation for users of your model\n",
    "    signature = mlflow.models.infer_signature(\n",
    "        X_train,               # Sample input data\n",
    "        model.predict(X_train) # Sample output (predictions)\n",
    "    )\n",
    "    \n",
    "    print(f\"    Input schema: {signature.inputs}\")\n",
    "    print(f\"    Output schema: {signature.outputs}\")\n",
    "    \n",
    "    # ===== STEP 6: Log the Model =====\n",
    "    print(\"\\n[5] Logging model with signature and input example...\")\n",
    "    \n",
    "    # Log the model with all metadata\n",
    "    # - \"random_forest_model\": Name of the model artifact folder\n",
    "    # - signature: Input/output schema\n",
    "    # - input_example: Sample input for documentation/testing\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,                          # The trained model object\n",
    "        \"random_forest_model\",          # Artifact folder name\n",
    "        signature=signature,            # Schema information\n",
    "        input_example=X_train.iloc[:3]  # First 3 rows as example\n",
    "    )\n",
    "    \n",
    "    print(f\"    Model logged successfully!\")\n",
    "    print(f\"    Run ID: {run.info.run_id}\")\n",
    "    \n",
    "    # Save run_id for later use\n",
    "    saved_run_id = run.info.run_id\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load the Model Back from MLflow\n",
    "\n",
    "Once a model is logged, you can load it back at any time. MLflow provides multiple ways to load models:\n",
    "\n",
    "1. **`mlflow.sklearn.load_model()`** - Returns native sklearn model\n",
    "2. **`mlflow.pyfunc.load_model()`** - Returns unified MLflow wrapper\n",
    "\n",
    "**Model URI Format:**\n",
    "- `runs:/<run_id>/<artifact_path>` - Load from a specific run\n",
    "- `models:/<model_name>/<version>` - Load from Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Model from MLflow\n",
      "============================================================\n",
      "Artifact URI from MLflow: mlflow-artifacts:/artifacts/14/807891a10ae5460e8bf7ab7a83e840d6/artifacts\n",
      "\n",
      "[1] Loading model from: /home/sujith/github/rag/airflow_mlflow_kubeflow/00_mlflow/docker/mlartifacts/artifacts/artifacts/14/807891a10ae5460e8bf7ab7a83e840d6/artifacts/random_forest_model\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/home/sujith/github/rag/airflow_mlflow_kubeflow/00_mlflow/docker/mlartifacts/artifacts/artifacts/14/807891a10ae5460e8bf7ab7a83e840d6/artifacts/random_forest_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[1] Loading model from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Load the model using sklearn flavor\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# This returns the native sklearn RandomForestClassifier object\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m loaded_model = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Model loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(loaded_model).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/rag/airflow_mlflow_kubeflow/00_mlflow/mlflow_usecases/.venv/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:652\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_uri, dst_path)\u001b[39m\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m(model_uri, dst_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    618\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    619\u001b[39m \u001b[33;03m    Load a scikit-learn model from a local file or a run.\u001b[39;00m\n\u001b[32m    620\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m        predictions = sk_model.predict(pandas_df)\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m     local_model_path = \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m     flavor_conf = _get_flavor_configuration(model_path=local_model_path, flavor_name=FLAVOR_NAME)\n\u001b[32m    654\u001b[39m     _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/rag/airflow_mlflow_kubeflow/00_mlflow/mlflow_usecases/.venv/lib/python3.13/site-packages/mlflow/tracking/artifact_utils.py:128\u001b[39m, in \u001b[36m_download_artifact_from_uri\u001b[39m\u001b[34m(artifact_uri, output_path, lineage_header_info, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m repo.download_artifacts(\n\u001b[32m    124\u001b[39m             artifact_path=artifact_path,\n\u001b[32m    125\u001b[39m             dst_path=output_path,\n\u001b[32m    126\u001b[39m             lineage_header_info=lineage_header_info,\n\u001b[32m    127\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artifact_uri.startswith(\u001b[33m\"\u001b[39m\u001b[33mm-\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    131\u001b[39m         \u001b[38;5;66;03m# When a Model ID like string is passed, suggest using 'models:/{artifact_uri}' instead.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/rag/airflow_mlflow_kubeflow/00_mlflow/mlflow_usecases/.venv/lib/python3.13/site-packages/mlflow/store/artifact/local_artifact_repo.py:93\u001b[39m, in \u001b[36mLocalArtifactRepository.download_artifacts\u001b[39m\u001b[34m(self, artifact_path, dst_path)\u001b[39m\n\u001b[32m     91\u001b[39m validate_path_within_directory(\u001b[38;5;28mself\u001b[39m.artifact_dir, local_artifact_path)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(local_artifact_path):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo such file or directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m os.path.abspath(local_artifact_path)\n",
      "\u001b[31mOSError\u001b[39m: No such file or directory: '/home/sujith/github/rag/airflow_mlflow_kubeflow/00_mlflow/docker/mlartifacts/artifacts/artifacts/14/807891a10ae5460e8bf7ab7a83e840d6/artifacts/random_forest_model'"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Loading Model from MLflow\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Construct the model URI (Uniform Resource Identifier)\n",
    "# Format: runs:/<run_id>/<artifact_path>\n",
    "model_uri = f\"runs:/{saved_run_id}/random_forest_model\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n[1] Loading model from: {model_uri}\")\n",
    "\n",
    "# Load the model using sklearn flavor\n",
    "# This returns the native sklearn RandomForestClassifier object\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(f\"    Model loaded successfully!\")\n",
    "print(f\"    Model type: {type(loaded_model).__name__}\")\n",
    "print(f\"    Number of trees: {loaded_model.n_estimators}\")\n",
    "print(f\"    Max depth: {loaded_model.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions with the Loaded Model\n",
    "\n",
    "Let's verify that the loaded model works correctly by making predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2] Making predictions with loaded model...\")\n",
    "\n",
    "# Take 5 samples from test data\n",
    "sample_data = X_test.iloc[:5]\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n    Sample Predictions:\")\n",
    "print(\"    \" + \"-\" * 55)\n",
    "print(f\"    {'#':<4} {'Predicted':<15} {'Actual':<15} {'Match'}\")\n",
    "print(\"    \" + \"-\" * 55)\n",
    "\n",
    "for i in range(5):\n",
    "    #actual_class = iris.target_names[y_test.iloc[i]]\n",
    "    actual_class = iris.target_names[y_test[i]]\n",
    "    predicted_class = iris.target_names[predictions[i]]\n",
    "    match = \"correct\" if actual_class == predicted_class else \"wrong\"\n",
    "    print(f\"    {i+1:<4} {predicted_class:<15} {actual_class:<15} {match}\")\n",
    "\n",
    "print(\"    \" + \"-\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Use the PyFunc Interface\n",
    "\n",
    "MLflow's **pyfunc** (Python Function) interface provides a unified way to load ANY model type. This is useful because:\n",
    "- Same loading code works for sklearn, TensorFlow, PyTorch, etc.\n",
    "- Easier to deploy to production\n",
    "- Consistent predict() interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[3] Testing pyfunc interface...\")\n",
    "\n",
    "# Load model using pyfunc interface\n",
    "# This returns an MLflow wrapper, not the native sklearn object\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "print(f\"    Model type: {type(pyfunc_model).__name__}\")\n",
    "\n",
    "# Make predictions - same predict() method, same results!\n",
    "pyfunc_predictions = pyfunc_model.predict(sample_data)\n",
    "\n",
    "print(f\"    Pyfunc predictions: {list(pyfunc_predictions)}\")\n",
    "\n",
    "# Verify predictions are identical\n",
    "if list(predictions) == list(pyfunc_predictions):\n",
    "    print(\"\\n    Both interfaces produce identical results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Full Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Full Classification Report (Loaded Model)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predictions for all test data\n",
    "all_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    all_predictions, \n",
    "    target_names=iris.target_names\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Model Logging Workflow\n",
    "\n",
    "### Step-by-Step Process\n",
    "\n",
    "```python\n",
    "# 1. Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # 2. Train your model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 3. Log parameters and metrics\n",
    "    mlflow.log_param(\"param_name\", value)\n",
    "    mlflow.log_metric(\"metric_name\", value)\n",
    "    \n",
    "    # 4. Create signature\n",
    "    signature = mlflow.models.infer_signature(X, model.predict(X))\n",
    "    \n",
    "    # 5. Log the model\n",
    "    mlflow.sklearn.log_model(model, \"model_name\", signature=signature)\n",
    "```\n",
    "\n",
    "### Loading Models\n",
    "\n",
    "```python\n",
    "# Load as native sklearn model\n",
    "model = mlflow.sklearn.load_model(\"runs:/<run_id>/model_name\")\n",
    "\n",
    "# Load as pyfunc (universal interface)\n",
    "model = mlflow.pyfunc.load_model(\"runs:/<run_id>/model_name\")\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Signature** | Defines expected input/output types |\n",
    "| **Input Example** | Sample data stored with model |\n",
    "| **Model URI** | Address to load model from |\n",
    "| **Flavor** | Framework-specific model type (sklearn, pytorch, etc.) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Model Logging Tutorial Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nView at: {TRACKING_URI}/#/experiments\")\n",
    "print(\"\\nWhat you learned:\")\n",
    "print(\"  1. How to log sklearn models with mlflow.sklearn.log_model()\")\n",
    "print(\"  2. How to create and use model signatures\")\n",
    "print(\"  3. How to store input examples with your model\")\n",
    "print(\"  4. How to load models using sklearn and pyfunc interfaces\")\n",
    "print(\"  5. How to make predictions with loaded models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel-std",
   "language": "python",
   "name": "kernel-std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
