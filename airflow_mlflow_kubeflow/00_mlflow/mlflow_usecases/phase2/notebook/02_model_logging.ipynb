{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2.2: Logging and Loading ML Models with MLflow\n",
    "\n",
    "This comprehensive notebook demonstrates:\n",
    "1. **Training an ML Model** - Build a RandomForest classifier\n",
    "2. **Logging Models** - Save models to MLflow with metadata\n",
    "3. **Model Signatures** - Define input/output schemas\n",
    "4. **Input Examples** - Store sample inputs with your model\n",
    "5. **Loading Models** - Retrieve models for predictions\n",
    "\n",
    "## What is Model Logging?\n",
    "\n",
    "**Model logging** saves your trained model to MLflow so you can:\n",
    "- **Reproduce** results later by loading the exact same model\n",
    "- **Deploy** models to production\n",
    "- **Compare** different model versions\n",
    "- **Share** models with your team\n",
    "\n",
    "## Learning Goals\n",
    "- Understand how to log sklearn models to MLflow\n",
    "- Learn about model signatures and why they matter\n",
    "- Know how to load models back for predictions\n",
    "- Use both `sklearn` and `pyfunc` interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "We'll use MLflow for experiment tracking and sklearn for building our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow: Main library for experiment tracking\n",
    "import mlflow\n",
    "\n",
    "# mlflow.sklearn: Special module for logging sklearn models\n",
    "# This provides optimized functions for sklearn model serialization\n",
    "import mlflow.sklearn\n",
    "\n",
    "# sklearn.datasets: Contains built-in datasets for practice\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# sklearn.model_selection: Tools for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sklearn.ensemble: Contains RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# sklearn.metrics: Functions to evaluate model performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# pandas: For working with tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# os: For environment variables\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to learn about model logging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to MLflow\n",
    "\n",
    "Connect to the MLflow tracking server and set up our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MLflow tracking server URL\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "\n",
    "# Tell MLflow where to send tracking data\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Create or select an experiment\n",
    "mlflow.set_experiment(\"phase2-model-logging\")\n",
    "\n",
    "print(f\"Connected to MLflow at: {TRACKING_URI}\")\n",
    "print(f\"Experiment: phase2-model-logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Explore the Dataset\n",
    "\n",
    "We'll use the classic **Iris dataset** - a simple dataset for classification that contains measurements of iris flowers.\n",
    "\n",
    "**Why use pandas DataFrame?**\n",
    "- Preserves feature names (important for signatures)\n",
    "- Better compatibility with MLflow\n",
    "- Easier to inspect and work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset from sklearn\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a pandas DataFrame with feature names as column headers\n",
    "# This is better than using raw numpy arrays because:\n",
    "# 1. Column names are preserved\n",
    "# 2. MLflow can infer better signatures\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Target variable (what we're trying to predict)\n",
    "y = iris.target\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Dataset Information\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset: Iris\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"\\nFeatures (measurements):\")\n",
    "for i, name in enumerate(iris.feature_names, 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "print(f\"\\nClasses (flower types):\")\n",
    "for i, name in enumerate(iris.target_names):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "print(f\"\\nFirst 5 samples:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split Data into Train and Test Sets\n",
    "\n",
    "We split the data to:\n",
    "- **Train** the model on 80% of the data\n",
    "- **Test** the model on the remaining 20% (unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# test_size=0.2 means 20% for testing\n",
    "# random_state=42 ensures reproducibility (same split every time)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Data split complete!\")\n",
    "print(f\"Training samples: {len(X_train)} (80%)\")\n",
    "print(f\"Testing samples: {len(X_test)} (20%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model and Log to MLflow\n",
    "\n",
    "Now let's train a RandomForest model and log everything to MLflow.\n",
    "\n",
    "**What gets logged:**\n",
    "1. Parameters (hyperparameters like n_estimators, max_depth)\n",
    "2. Metrics (performance scores like accuracy)\n",
    "3. Model (the trained model itself)\n",
    "4. Signature (input/output schema)\n",
    "5. Input example (sample input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Training and Logging Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start an MLflow run - all logs will be grouped under this run\n",
    "with mlflow.start_run(run_name=\"model-logging-demo\") as run:\n",
    "    \n",
    "    # ===== STEP 1: Train the Model =====\n",
    "    print(\"\\n[1] Training model...\")\n",
    "    \n",
    "    # Create a RandomForest classifier\n",
    "    # - n_estimators: Number of trees in the forest (more trees = better but slower)\n",
    "    # - max_depth: How deep each tree can grow (prevents overfitting)\n",
    "    # - random_state: Ensures reproducibility\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,  # Use 100 decision trees\n",
    "        max_depth=5,       # Limit tree depth to 5 levels\n",
    "        random_state=42    # For reproducibility\n",
    "    )\n",
    "    \n",
    "    # Train the model on training data\n",
    "    # The model learns patterns from X_train to predict y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ===== STEP 2: Evaluate the Model =====\n",
    "    # Use the trained model to predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy: percentage of correct predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"    Accuracy: {accuracy:.4f} ({accuracy*100:.1f}% correct)\")\n",
    "    \n",
    "    # ===== STEP 3: Log Parameters =====\n",
    "    # Parameters are the configuration settings you chose\n",
    "    print(\"\\n[2] Logging parameters...\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 5)\n",
    "    print(\"    Logged: n_estimators=100, max_depth=5\")\n",
    "    \n",
    "    # ===== STEP 4: Log Metrics =====\n",
    "    # Metrics are numerical performance measurements\n",
    "    print(\"\\n[3] Logging metrics...\")\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    print(f\"    Logged: accuracy={accuracy:.4f}\")\n",
    "    \n",
    "    # ===== STEP 5: Create Model Signature =====\n",
    "    print(\"\\n[4] Creating model signature...\")\n",
    "    \n",
    "    # Signature describes what the model expects as input and produces as output\n",
    "    # This is crucial for:\n",
    "    # - Model validation when loading\n",
    "    # - Automatic type checking in production\n",
    "    # - Documentation for users of your model\n",
    "    signature = mlflow.models.infer_signature(\n",
    "        X_train,               # Sample input data\n",
    "        model.predict(X_train) # Sample output (predictions)\n",
    "    )\n",
    "    \n",
    "    print(f\"    Input schema: {signature.inputs}\")\n",
    "    print(f\"    Output schema: {signature.outputs}\")\n",
    "    \n",
    "    # ===== STEP 6: Log the Model =====\n",
    "    print(\"\\n[5] Logging model with signature and input example...\")\n",
    "    \n",
    "    # Log the model with all metadata\n",
    "    # - \"random_forest_model\": Name of the model artifact folder\n",
    "    # - signature: Input/output schema\n",
    "    # - input_example: Sample input for documentation/testing\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,                          # The trained model object\n",
    "        \"random_forest_model\",          # Artifact folder name\n",
    "        signature=signature,            # Schema information\n",
    "        input_example=X_train.iloc[:3]  # First 3 rows as example\n",
    "    )\n",
    "    \n",
    "    print(f\"    Model logged successfully!\")\n",
    "    print(f\"    Run ID: {run.info.run_id}\")\n",
    "    \n",
    "    # Save run_id for later use\n",
    "    saved_run_id = run.info.run_id\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load the Model Back from MLflow\n",
    "\n",
    "Once a model is logged, you can load it back at any time. MLflow provides multiple ways to load models:\n",
    "\n",
    "1. **`mlflow.sklearn.load_model()`** - Returns native sklearn model\n",
    "2. **`mlflow.pyfunc.load_model()`** - Returns unified MLflow wrapper\n",
    "\n",
    "**Model URI Format:**\n",
    "- `runs:/<run_id>/<artifact_path>` - Load from a specific run\n",
    "- `models:/<model_name>/<version>` - Load from Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Loading Model from MLflow\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Construct the model URI (Uniform Resource Identifier)\n",
    "# Format: runs:/<run_id>/<artifact_path>\n",
    "model_uri = f\"runs:/{saved_run_id}/random_forest_model\"\n",
    "\n",
    "print(f\"\\n[1] Loading model from: {model_uri}\")\n",
    "\n",
    "# Load the model using sklearn flavor\n",
    "# This returns the native sklearn RandomForestClassifier object\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(f\"    Model loaded successfully!\")\n",
    "print(f\"    Model type: {type(loaded_model).__name__}\")\n",
    "print(f\"    Number of trees: {loaded_model.n_estimators}\")\n",
    "print(f\"    Max depth: {loaded_model.max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions with the Loaded Model\n",
    "\n",
    "Let's verify that the loaded model works correctly by making predictions on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2] Making predictions with loaded model...\")\n",
    "\n",
    "# Take 5 samples from test data\n",
    "sample_data = X_test.iloc[:5]\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n    Sample Predictions:\")\n",
    "print(\"    \" + \"-\" * 55)\n",
    "print(f\"    {'#':<4} {'Predicted':<15} {'Actual':<15} {'Match'}\")\n",
    "print(\"    \" + \"-\" * 55)\n",
    "\n",
    "for i in range(5):\n",
    "    actual_class = iris.target_names[y_test.iloc[i]]\n",
    "    predicted_class = iris.target_names[predictions[i]]\n",
    "    match = \"correct\" if actual_class == predicted_class else \"wrong\"\n",
    "    print(f\"    {i+1:<4} {predicted_class:<15} {actual_class:<15} {match}\")\n",
    "\n",
    "print(\"    \" + \"-\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Use the PyFunc Interface\n",
    "\n",
    "MLflow's **pyfunc** (Python Function) interface provides a unified way to load ANY model type. This is useful because:\n",
    "- Same loading code works for sklearn, TensorFlow, PyTorch, etc.\n",
    "- Easier to deploy to production\n",
    "- Consistent predict() interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[3] Testing pyfunc interface...\")\n",
    "\n",
    "# Load model using pyfunc interface\n",
    "# This returns an MLflow wrapper, not the native sklearn object\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "print(f\"    Model type: {type(pyfunc_model).__name__}\")\n",
    "\n",
    "# Make predictions - same predict() method, same results!\n",
    "pyfunc_predictions = pyfunc_model.predict(sample_data)\n",
    "\n",
    "print(f\"    Pyfunc predictions: {list(pyfunc_predictions)}\")\n",
    "\n",
    "# Verify predictions are identical\n",
    "if list(predictions) == list(pyfunc_predictions):\n",
    "    print(\"\\n    Both interfaces produce identical results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Full Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Full Classification Report (Loaded Model)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get predictions for all test data\n",
    "all_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    all_predictions, \n",
    "    target_names=iris.target_names\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Model Logging Workflow\n",
    "\n",
    "### Step-by-Step Process\n",
    "\n",
    "```python\n",
    "# 1. Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # 2. Train your model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 3. Log parameters and metrics\n",
    "    mlflow.log_param(\"param_name\", value)\n",
    "    mlflow.log_metric(\"metric_name\", value)\n",
    "    \n",
    "    # 4. Create signature\n",
    "    signature = mlflow.models.infer_signature(X, model.predict(X))\n",
    "    \n",
    "    # 5. Log the model\n",
    "    mlflow.sklearn.log_model(model, \"model_name\", signature=signature)\n",
    "```\n",
    "\n",
    "### Loading Models\n",
    "\n",
    "```python\n",
    "# Load as native sklearn model\n",
    "model = mlflow.sklearn.load_model(\"runs:/<run_id>/model_name\")\n",
    "\n",
    "# Load as pyfunc (universal interface)\n",
    "model = mlflow.pyfunc.load_model(\"runs:/<run_id>/model_name\")\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Signature** | Defines expected input/output types |\n",
    "| **Input Example** | Sample data stored with model |\n",
    "| **Model URI** | Address to load model from |\n",
    "| **Flavor** | Framework-specific model type (sklearn, pytorch, etc.) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Model Logging Tutorial Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nView at: {TRACKING_URI}/#/experiments\")\n",
    "print(\"\\nWhat you learned:\")\n",
    "print(\"  1. How to log sklearn models with mlflow.sklearn.log_model()\")\n",
    "print(\"  2. How to create and use model signatures\")\n",
    "print(\"  3. How to store input examples with your model\")\n",
    "print(\"  4. How to load models using sklearn and pyfunc interfaces\")\n",
    "print(\"  5. How to make predictions with loaded models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
