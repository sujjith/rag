{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3.4: Complete Model Registry Workflow\n",
    "\n",
    "This comprehensive notebook demonstrates a **real-world ML workflow**:\n",
    "1. Train initial model\n",
    "2. Register in registry\n",
    "3. Promote to Staging\n",
    "4. Test in Staging\n",
    "5. Promote to Production\n",
    "6. Train improved model\n",
    "7. Compare and promote new version\n",
    "\n",
    "## The MLOps Workflow\n",
    "\n",
    "```\n",
    "┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n",
    "│   DEVELOP   │────>│   STAGING   │────>│ PRODUCTION  │\n",
    "│             │     │             │     │             │\n",
    "│ Train Model │     │ Run Tests   │     │ Serve Users │\n",
    "│ Log to MLflow     │ Validate    │     │ Monitor     │\n",
    "│ Register    │     │ Compare     │     │             │\n",
    "└─────────────┘     └─────────────┘     └─────────────┘\n",
    "```\n",
    "\n",
    "## Learning Goals\n",
    "- Understand the full ML lifecycle\n",
    "- Practice promoting models through stages\n",
    "- Compare model versions programmatically\n",
    "- Implement production deployment patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data handling and utilities\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to learn the complete registry workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MLflow tracking server URL\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "\n",
    "# Connect to MLflow\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(\"phase3-workflow\")\n",
    "\n",
    "# Model name for this workflow\n",
    "MODEL_NAME = \"iris-production-workflow\"\n",
    "\n",
    "# Create client\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"Connected to MLflow at: {TRACKING_URI}\")\n",
    "print(f\"Experiment: phase3-workflow\")\n",
    "print(f\"Model name: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Helper Functions\n",
    "\n",
    "We'll create reusable functions for common operations. This is how you'd organize code in a real project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, run_name):\n",
    "    \"\"\"\n",
    "    Train and log a model to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        params: Dictionary of model parameters\n",
    "        run_name: Name for the MLflow run\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (run_id, accuracy)\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    iris = load_iris()\n",
    "    X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    y = iris.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train and log\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        return run.info.run_id, accuracy\n",
    "\n",
    "\n",
    "def register_model(run_id, model_name):\n",
    "    \"\"\"\n",
    "    Register a model from a run.\n",
    "    \n",
    "    Args:\n",
    "        run_id: The MLflow run ID\n",
    "        model_name: Name for the registered model\n",
    "    \n",
    "    Returns:\n",
    "        str: The version number\n",
    "    \"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    result = mlflow.register_model(model_uri, model_name)\n",
    "    return result.version\n",
    "\n",
    "\n",
    "def promote_to_stage(model_name, version, stage, archive_existing=False):\n",
    "    \"\"\"\n",
    "    Promote a model version to a stage.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "        version: Version number to promote\n",
    "        stage: Target stage (Staging, Production, Archived)\n",
    "        archive_existing: Whether to archive existing versions in the target stage\n",
    "    \"\"\"\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=str(version),\n",
    "        stage=stage,\n",
    "        archive_existing_versions=archive_existing\n",
    "    )\n",
    "\n",
    "\n",
    "def load_and_test(model_name, stage):\n",
    "    \"\"\"\n",
    "    Load a model from a stage and run tests.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "        stage: Stage to load from\n",
    "    \n",
    "    Returns:\n",
    "        float: Test accuracy\n",
    "    \"\"\"\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{model_name}/{stage}\")\n",
    "    \n",
    "    # Load test data\n",
    "    iris = load_iris()\n",
    "    X_test = pd.DataFrame(iris.data[:10], columns=iris.feature_names)\n",
    "    y_test = iris.target[:10]\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = (predictions == y_test).mean()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "print(\"Helper functions defined:\")\n",
    "print(\"  - train_model(params, run_name)\")\n",
    "print(\"  - register_model(run_id, model_name)\")\n",
    "print(\"  - promote_to_stage(model_name, version, stage)\")\n",
    "print(\"  - load_and_test(model_name, stage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Clean Up (For Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up existing model for a fresh demo\n",
    "try:\n",
    "    client.delete_registered_model(MODEL_NAME)\n",
    "    print(f\"Cleaned up existing model: {MODEL_NAME}\")\n",
    "except:\n",
    "    print(f\"No existing model to clean up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 1: Train Initial Model\n",
    "\n",
    "Start with a baseline model using conservative hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ML MODEL REGISTRY WORKFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[Step 1] Training Initial Model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Conservative initial parameters\n",
    "params_v1 = {\"n_estimators\": 50, \"max_depth\": 5}\n",
    "\n",
    "run_id_v1, accuracy_v1 = train_model(params_v1, \"initial-model\")\n",
    "\n",
    "print(f\"  Parameters: {params_v1}\")\n",
    "print(f\"  Accuracy: {accuracy_v1:.4f}\")\n",
    "print(f\"  Run ID: {run_id_v1[:8]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 2: Register Model\n",
    "\n",
    "Add the model to the Model Registry for versioning and lifecycle management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 2] Registering Model in Registry\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "version_v1 = register_model(run_id_v1, MODEL_NAME)\n",
    "\n",
    "print(f\"  Registered as: {MODEL_NAME}\")\n",
    "print(f\"  Version: {version_v1}\")\n",
    "\n",
    "# Wait for registration to complete\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 3: Promote to Staging\n",
    "\n",
    "Move the model to Staging for testing before production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 3] Promoting to Staging for Testing\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "promote_to_stage(MODEL_NAME, version_v1, \"Staging\")\n",
    "\n",
    "print(f\"  Version {version_v1} -> Staging\")\n",
    "print(\"  (Model is now available for validation testing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 4: Test in Staging\n",
    "\n",
    "Run validation tests on the staging model before promoting to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 4] Running Tests in Staging\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "staging_accuracy = load_and_test(MODEL_NAME, \"Staging\")\n",
    "\n",
    "print(f\"  Staging test accuracy: {staging_accuracy:.4f}\")\n",
    "\n",
    "# Define acceptance criteria\n",
    "ACCEPTANCE_THRESHOLD = 0.8\n",
    "\n",
    "if staging_accuracy >= ACCEPTANCE_THRESHOLD:\n",
    "    print(f\"  Tests PASSED! (threshold: {ACCEPTANCE_THRESHOLD})\")\n",
    "    staging_passed = True\n",
    "else:\n",
    "    print(f\"  Tests FAILED! (threshold: {ACCEPTANCE_THRESHOLD})\")\n",
    "    staging_passed = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 5: Promote to Production\n",
    "\n",
    "If tests pass, promote the model to Production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 5] Promoting to Production\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if staging_passed:\n",
    "    promote_to_stage(MODEL_NAME, version_v1, \"Production\")\n",
    "    print(f\"  Version {version_v1} -> Production\")\n",
    "    print(\"  (Model is now serving live traffic)\")\n",
    "else:\n",
    "    print(\"  Skipping - staging tests did not pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 6: Train Improved Model\n",
    "\n",
    "Train a new model with better hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 6] Training Improved Model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# More aggressive parameters for improved model\n",
    "params_v2 = {\"n_estimators\": 100, \"max_depth\": 10}\n",
    "\n",
    "run_id_v2, accuracy_v2 = train_model(params_v2, \"improved-model\")\n",
    "\n",
    "print(f\"  Parameters: {params_v2}\")\n",
    "print(f\"  Accuracy: {accuracy_v2:.4f}\")\n",
    "print(f\"  Run ID: {run_id_v2[:8]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 7: Register New Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 7] Registering Improved Model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "version_v2 = register_model(run_id_v2, MODEL_NAME)\n",
    "\n",
    "print(f\"  Registered as: {MODEL_NAME}\")\n",
    "print(f\"  Version: {version_v2}\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 8: Compare Models\n",
    "\n",
    "Compare the new model against the current production model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 8] Comparing Models\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\"  Production (v{version_v1}): accuracy = {accuracy_v1:.4f}\")\n",
    "print(f\"  Candidate  (v{version_v2}): accuracy = {accuracy_v2:.4f}\")\n",
    "\n",
    "improvement = accuracy_v2 - accuracy_v1\n",
    "print(f\"\\n  Improvement: {improvement:+.4f}\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"  Result: New model is BETTER\")\n",
    "elif improvement < 0:\n",
    "    print(\"  Result: New model is WORSE\")\n",
    "else:\n",
    "    print(\"  Result: Models are EQUAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 9: Make Promotion Decision\n",
    "\n",
    "Decide whether to promote the new model to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 9] Making Promotion Decision\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "if accuracy_v2 > accuracy_v1:\n",
    "    print(\"  Decision: PROMOTE new model to Production\")\n",
    "    \n",
    "    # First, send to Staging for testing\n",
    "    promote_to_stage(MODEL_NAME, version_v2, \"Staging\")\n",
    "    print(f\"\\n  Version {version_v2} -> Staging\")\n",
    "    \n",
    "    # Run staging tests\n",
    "    staging_accuracy = load_and_test(MODEL_NAME, \"Staging\")\n",
    "    print(f\"  Staging tests passed (accuracy: {staging_accuracy:.4f})\")\n",
    "    \n",
    "    # Promote to Production (archive_existing=True auto-archives old production)\n",
    "    promote_to_stage(MODEL_NAME, version_v2, \"Production\", archive_existing=True)\n",
    "    print(f\"\\n  Version {version_v2} -> Production\")\n",
    "    print(f\"  Version {version_v1} -> Archived (automatically)\")\n",
    "    \n",
    "else:\n",
    "    print(\"  Decision: KEEP current Production model\")\n",
    "    \n",
    "    # Archive the candidate since it's not better\n",
    "    promote_to_stage(MODEL_NAME, version_v2, \"Archived\")\n",
    "    print(f\"\\n  Version {version_v2} -> Archived (not better than production)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Registry State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL REGISTRY STATE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nModel: {MODEL_NAME}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for mv in client.search_model_versions(f\"name='{MODEL_NAME}'\"):\n",
    "    # Get run metrics\n",
    "    run = client.get_run(mv.run_id)\n",
    "    accuracy = run.data.metrics.get(\"accuracy\", 0)\n",
    "    \n",
    "    print(f\"  Version {mv.version}: {mv.current_stage:12s} (accuracy: {accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Verify Production Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(\"Verifying Production Model\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Load the current production model\n",
    "prod_model = mlflow.pyfunc.load_model(f\"models:/{MODEL_NAME}/Production\")\n",
    "\n",
    "print(\"\\nProduction model loaded successfully!\")\n",
    "print(\"Ready for inference.\")\n",
    "\n",
    "# Quick test\n",
    "iris = load_iris()\n",
    "test_sample = pd.DataFrame([iris.data[0]], columns=iris.feature_names)\n",
    "prediction = prod_model.predict(test_sample)\n",
    "\n",
    "print(f\"\\nSample prediction: {iris.target_names[prediction[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Complete MLOps Workflow\n",
    "\n",
    "### The 9-Step Workflow\n",
    "\n",
    "```\n",
    "1. Train Model       -> Create initial model\n",
    "2. Register          -> Add to Model Registry\n",
    "3. Stage             -> Move to Staging\n",
    "4. Test              -> Run validation tests\n",
    "5. Deploy            -> Promote to Production\n",
    "6. Iterate           -> Train improved model\n",
    "7. Register          -> Create new version\n",
    "8. Compare           -> Evaluate against production\n",
    "9. Promote/Archive   -> Deploy or discard\n",
    "```\n",
    "\n",
    "### Key Patterns\n",
    "\n",
    "| Pattern | Purpose |\n",
    "|---------|----------|\n",
    "| Staging tests | Validate before production |\n",
    "| Model comparison | Data-driven promotion decisions |\n",
    "| Auto-archive | Clean up old production versions |\n",
    "| Stage-based loading | Consistent production access |\n",
    "\n",
    "### Production Code Pattern\n",
    "\n",
    "```python\n",
    "# Your inference service just needs:\n",
    "model = mlflow.pyfunc.load_model(\"models:/my-model/Production\")\n",
    "predictions = model.predict(data)\n",
    "\n",
    "# When you promote a new model, this code automatically uses it!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Registry Workflow Tutorial Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nView at: {TRACKING_URI}/#/models/{MODEL_NAME}\")\n",
    "print(\"\\nWhat you learned:\")\n",
    "print(\"  1. The complete ML model lifecycle\")\n",
    "print(\"  2. How to structure helper functions for MLOps\")\n",
    "print(\"  3. How to test models in Staging before Production\")\n",
    "print(\"  4. How to compare model versions programmatically\")\n",
    "print(\"  5. How to safely promote new models to Production\")\n",
    "print(\"  6. How to archive old models automatically\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
