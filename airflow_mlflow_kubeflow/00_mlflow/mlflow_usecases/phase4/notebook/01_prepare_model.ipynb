{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4.1: Preparing a Model for Serving\n",
    "\n",
    "This comprehensive notebook demonstrates:\n",
    "1. **Training a Production-Ready Model** - Build a model ready for deployment\n",
    "2. **Proper Signature** - Ensure input/output schemas are defined\n",
    "3. **Input Examples** - Include sample inputs with the model\n",
    "4. **Registration & Promotion** - Deploy to Production stage\n",
    "\n",
    "## What is Model Serving?\n",
    "\n",
    "**Model Serving** means making your trained model available as an API endpoint that can receive requests and return predictions.\n",
    "\n",
    "```\n",
    "Client Request          Model Server          Response\n",
    "    │                       │                    │\n",
    "    │  {\"features\": [...]}  │                    │\n",
    "    │ ─────────────────────>│                    │\n",
    "    │                       │  Load Model        │\n",
    "    │                       │  Make Prediction   │\n",
    "    │                       │<───────────────────│\n",
    "    │   {\"prediction\": 0}   │                    │\n",
    "    │<──────────────────────│                    │\n",
    "```\n",
    "\n",
    "## Prerequisites for Serving\n",
    "\n",
    "A model needs these things to be served:\n",
    "1. ✅ **Signature** - Defines expected input/output format\n",
    "2. ✅ **Input Example** - Sample data for testing\n",
    "3. ✅ **Registered** - In the Model Registry\n",
    "4. ✅ **Stage** - Promoted to Production (or Staging)\n",
    "\n",
    "## Learning Goals\n",
    "- Prepare a model for serving\n",
    "- Include proper signatures and examples\n",
    "- Register and promote to Production\n",
    "- Understand the serving command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow imports\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Ready to prepare a model for serving!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Connect to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MLflow tracking server URL\n",
    "TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://localhost:5000\")\n",
    "\n",
    "# Connect to MLflow\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(\"phase4-serving\")\n",
    "\n",
    "# Model name for serving\n",
    "MODEL_NAME = \"iris-serving-model\"\n",
    "\n",
    "# Create client\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"Connected to MLflow at: {TRACKING_URI}\")\n",
    "print(f\"Experiment: phase4-serving\")\n",
    "print(f\"Model name: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean Up Existing Model (For Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up existing model for fresh demo\n",
    "try:\n",
    "    client.delete_registered_model(MODEL_NAME)\n",
    "    print(f\"Cleaned up existing model: {MODEL_NAME}\")\n",
    "except:\n",
    "    print(\"No existing model to clean up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create DataFrame with feature names\n",
    "# Using a DataFrame is important for proper signatures!\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Create target as a Series with name\n",
    "y = pd.Series(iris.target, name=\"species\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Preparing Model for Serving\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDataset: Iris\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Classes: {list(iris.target_names)}\")\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model with Full Logging\n",
    "\n",
    "We'll train a model and log everything needed for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[1] Training Model\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with mlflow.start_run(run_name=\"serving-model\") as run:\n",
    "    # Train a production-quality model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Show classification report\n",
    "    print(f\"\\n  Classification Report:\")\n",
    "    report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
    "    for line in report.split('\\n'):\n",
    "        print(f\"    {line}\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 10)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # ========================================\n",
    "    # CRITICAL FOR SERVING: Create Signature\n",
    "    # ========================================\n",
    "    print(\"\\n[2] Creating Model Signature\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # The signature defines what input the model expects\n",
    "    # and what output it produces\n",
    "    signature = mlflow.models.infer_signature(\n",
    "        X_train,                    # Sample input\n",
    "        model.predict(X_train)      # Sample output\n",
    "    )\n",
    "    \n",
    "    print(f\"  Input schema:\")\n",
    "    print(f\"    {signature.inputs}\")\n",
    "    print(f\"  Output schema:\")\n",
    "    print(f\"    {signature.outputs}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # CRITICAL FOR SERVING: Log with Metadata\n",
    "    # ========================================\n",
    "    print(\"\\n[3] Logging Model with Serving Metadata\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Log the model with:\n",
    "    # 1. signature - Input/output schema\n",
    "    # 2. input_example - Sample data for testing\n",
    "    # 3. registered_model_name - Auto-register\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        \"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train.iloc[:2],  # First 2 rows as example\n",
    "        registered_model_name=MODEL_NAME  # Auto-register!\n",
    "    )\n",
    "    \n",
    "    print(f\"  Model logged and registered!\")\n",
    "    print(f\"  Run ID: {run.info.run_id}\")\n",
    "    \n",
    "    saved_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Promote to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[4] Promoting to Production\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Wait for registration to complete\n",
    "time.sleep(2)\n",
    "\n",
    "# Get the latest version\n",
    "latest_versions = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "\n",
    "if latest_versions:\n",
    "    latest = latest_versions[0]\n",
    "    \n",
    "    # Promote to Production\n",
    "    client.transition_model_version_stage(\n",
    "        name=MODEL_NAME,\n",
    "        version=latest.version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  Version {latest.version} -> Production\")\n",
    "else:\n",
    "    print(\"  No version found to promote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify Model is Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[5] Verifying Model is Ready for Serving\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load the production model\n",
    "prod_model = mlflow.pyfunc.load_model(f\"models:/{MODEL_NAME}/Production\")\n",
    "\n",
    "# Test predictions\n",
    "test_predictions = prod_model.predict(X_test[:3])\n",
    "\n",
    "print(f\"  Test predictions: {list(test_predictions)}\")\n",
    "print(f\"  Expected:         {list(y_test[:3])}\")\n",
    "print(f\"\\n  Model is ready for serving!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Model Ready for Serving\n",
    "\n",
    "Here's what we've done to prepare the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL READY FOR SERVING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get version info\n",
    "latest = client.get_latest_versions(MODEL_NAME, stages=[\"Production\"])[0]\n",
    "\n",
    "print(f\"\\n  Model name: {MODEL_NAME}\")\n",
    "print(f\"  Version: {latest.version}\")\n",
    "print(f\"  Stage: Production\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"HOW TO SERVE THIS MODEL\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Option 1: MLflow CLI\n",
    "  mlflow models serve -m 'models:/{MODEL_NAME}/Production' -p 5001 --no-conda\n",
    "\n",
    "Option 2: Docker\n",
    "  mlflow models build-docker -m 'models:/{MODEL_NAME}/Production' -n my-model\n",
    "  docker run -p 5001:8080 my-model\n",
    "\n",
    "Option 3: Custom script\n",
    "  Use ./scripts/serve-model.sh {MODEL_NAME} Production\n",
    "\"\"\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"MAKING PREDICTIONS (after starting server)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "curl -X POST http://localhost:5001/invocations \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{{\"inputs\": [[5.1, 3.5, 1.4, 0.2]]}}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points for Model Serving\n",
    "\n",
    "### Checklist Before Serving\n",
    "\n",
    "| Requirement | Why It's Needed |\n",
    "|-------------|----------------|\n",
    "| **Signature** | Validates input format at runtime |\n",
    "| **Input Example** | Enables testing and documentation |\n",
    "| **Registered** | Enables versioning and stage management |\n",
    "| **Production Stage** | Indicates model is ready for live traffic |\n",
    "\n",
    "### Model Logging for Serving\n",
    "\n",
    "```python\n",
    "# Include ALL metadata when logging\n",
    "mlflow.sklearn.log_model(\n",
    "    model,\n",
    "    \"model\",\n",
    "    signature=signature,           # Required for validation\n",
    "    input_example=sample_data,     # For testing\n",
    "    registered_model_name=\"name\"   # Auto-register\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Preparing Model for Serving - Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nView at: {TRACKING_URI}\")\n",
    "print(\"\\nWhat you learned:\")\n",
    "print(\"  1. What model serving is and why it matters\")\n",
    "print(\"  2. How to create model signatures\")\n",
    "print(\"  3. How to include input examples\")\n",
    "print(\"  4. How to register and promote models\")\n",
    "print(\"  5. Commands to serve the model\")\n",
    "print(\"\\nNext: Run 02_test_serving.ipynb to test the serving endpoint!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
